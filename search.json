[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Note: this is an abbreviated syllabus. The full syllabus is available through Classmate and/or Canvas.\n\nInstructor Information\n\nDr. Samantha Seals\nOffice: 4/344\n\n\n\nMeeting Times and Location\n\nMW 1:00-2:15 pm\nClassroom: 51/152\n\n\n\nOffice Hours\n\nMonday: 2:30–4:30 pm (Central)\nWednesday: 2:30–4:30 pm (Central)\nThursday: 10:00 am–12:00 pm (Central)\nOther times by appointment\n\n\n\nGrading and Evaluation\nThe course grade will be determined as follows:\n\nAssignments (25%): Each module will include an activity for students to complete using Quarto and R. The resulting .html file should be submitted to the designated dropbox on Canvas by 11:59 pm on the specified date (see Canvas).\nProject (40%): You will work with your research team to complete a research project. There will be several check ins completed during the project period. The resulting .pdf file should be submitted to the designated dropbox on Canvas by 11:59 pm on the specified date (see Canvas).\nOUR Symposium (10%): Each team will put together a research poster based on the project. All research teams will present their poster at the symposium.\nFinal Exam (25%): The final exam will be a timed concepts-based exam. While there may be some calculations needed, you will not be processing raw data. The final exam will be in class 11:00 am-1:30 pm on April 30, 2025.\n\n\n\nLate Policy\nAssigments have due dates, however, the dropboxes will not close until the end of the semester. All students are automatically granted “extensions” without question.\nNote that if there is not a submission when I go to grade (after the initial deadline), I will assign a zero (0) and request that you submit the assignment when you are able to. This is only for record keeping purposes. There is no penalty for submitting late and a full grade will be given upon review of your submission.\nExtensions are not available for the projects or final exam.\n\n\nImportant University Dates\n\n\n\n\n\n\n\nDate\nEvent\n\n\n\n\nJan 8 (Mon)\nSpring begins.\n\n\nJan 14 (Tues)\nDrop/Add period ends.\n\n\nJan 20 (Mon)\nMartin Luther King’s birthday - campus closed.\n\n\nMar 17-23 (Mon-Fri)\nSpring Break - campus closed.\n\n\nApr 7 (Mon)\nWithdrawal deadline (automatic grade of “W”).\n\n\nMay 5 (Fri)\nLate withdrawal deadline (“W” or “WF”, see requirements below)."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-analysis-of-variance",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-analysis-of-variance",
    "title": "One-Way Analysis of Variance",
    "section": "Introduction: Analysis of Variance",
    "text": "Introduction: Analysis of Variance\n\nWe have previously discussed testing the difference between two groups.\n\nWhat about when there are three or more groups?\n\nWe will use a method called analysis of variance (ANOVA).\n\nThis method partitions the variance of the outcome into variance due to the groups and variance due to “other” factors.\n\nFun fact: the two-sample t-test is a special case of ANOVA.\n\nIf you perform ANOVA when comparing two means, you will obtain the same results as the two-sample t-test."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#hypotheses",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#hypotheses",
    "title": "One-Way Analysis of Variance",
    "section": "Hypotheses",
    "text": "Hypotheses\n\nHypotheses all take the same form:\n\nH_0: \\ \\mu_1 = \\mu_2 = ... = \\mu_k\nH_1: at least one is different\n\nNote 1: you must fill in the “k” when writing hypotheses!\n\ne.g., if there are four means, your hypotheses are\n\nH_0: \\ \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4\nH_1: at least one is different\n\n\nNote 2: ANOVA does not tell us which means are different, just if a general difference exists!"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-table",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-table",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Table",
    "text": "ANOVA Table\n\nThe computations for ANOVA are more involved than what we’ve seen before.\nAn ANOVA table will be constructed in order to perform the hypothesis test.\n\n\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares\ndf\nMean Squares\nF\n\n\n\n\nTreatment\nSSTrt\ndfTrt\nMSTrt\nF0\n\n\nError\nSSE\ndfE\nMSE\n\n\n\nTotal\nSSTot\ndfTot\n\n\n\n\n\n\nOnce this is put together, we can perform the hypothesis test.\n\nOur test statistic is the F0."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#the-f-distribution",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#the-f-distribution",
    "title": "One-Way Analysis of Variance",
    "section": "The F Distribution",
    "text": "The F Distribution\n\nThe F distribution is derived as the ratio of two variances.\n\nThe variances each have degrees of freedom: dfnumerator and dfdenominator\n\nThe F distribution’s shape depends on the df,"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Computations",
    "text": "ANOVA Computations\n\nAgain, here’s where we are headed with our computations:\n\n\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares\ndf\nMean Squares\nF\n\n\n\n\nTreatment\nSSTrt\ndfTrt\nMSTrt\nF0\n\n\nError\nSSE\ndfE\nMSE\n\n\n\nTotal\nSSTot\ndfTot\n\n\n\n\n\n\nWe are partitioning the variance of our outcome into:\n\nVariance due to the grouping (treatment)\nVariance due to “other” factors (error)\n\nThink of this like a “catch all” for other sources of error – things we did not adjust for in our model."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-1",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-1",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Computations",
    "text": "ANOVA Computations\n\nBefore we begin our computations, it would be helpful if we know\n\n \\bar{x}, \\ \\ n_i, \\ \\ \\bar{x}_i, \\ \\ s_i^2 \n\nwhere,\n\n\\bar{x} is the overall mean,\nn_i is the sample size for group i,\n\\bar{x}_i is the mean for group i, and\ns_i^2 is the variance for group i"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-2",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-2",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Computations",
    "text": "ANOVA Computations\n\nWe begin our computations with the sums of squares:\n\n\n\\begin{align*}\n    \\text{SS}_{\\text{Trt}} &= \\sum_{i=1}^k n_i(\\bar{x}_i-\\bar{x})^2 \\\\\n    \\text{SS}_{\\text{E}} &= \\sum_{i=1}^k (n_i-1)s_i^2 \\\\\n    \\text{SS}_{\\text{Tot}} &= \\text{SS}_{\\text{Trt}} + \\text{SS}_{\\text{E}}\n\\end{align*}\n\n\nand each sum of squares has degrees of freedom:\n\n\\text{df}_{\\text{Trt}} = k-1 (number of groups – 1)\n\\text{df}_{\\text{E}} = n-k (overall sample size – number of groups)\n\\text{df}_{\\text{Tot}} = n-1 (overall sample size – 1) = \\text{df}_{\\text{Trt}} + \\text{df}_{\\text{E}}"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-3",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-3",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Computations",
    "text": "ANOVA Computations\n\nOnce we have the sum of squares and corresponding degrees of freedom, we have the mean squares.\nGenerally, mean squares are the sum of square divided by the df,  \\text{MS}_X = \\frac{\\text{SS}_X}{\\text{df}_X}\nIn the case of one-way ANOVA, \n\\begin{align*}\n  \\text{MS}_{\\text{Trt}} &= \\frac{\\text{SS}_{\\text{Trt}}}{\\text{df}_{\\text{Trt}}} \\\\\n  \\text{MS}_{\\text{E}} &= \\frac{\\text{SS}_{\\text{E}}}{\\text{df}_{\\text{E}}}\n\\end{align*}\n\n\nNote that there is no \\text{MS}_{\\text{Tot}}!"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-4",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-4",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Computations",
    "text": "ANOVA Computations\n\nFinally, we have the test statistic.\nGenerally, we construct an F for ANOVA by dividing the MS of interest by MS_{\\text{E}},  F_X = \\frac{\\text{MS}_X}{\\text{MS}_{\\text{E}}} \nIn one-way ANOVA, we are only constructing the F for treatment, F_0 = \\frac{\\text{MS}_{\\text{Trt}}}{\\text{MS}_{\\text{E}}}"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-5",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-computations-5",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA Computations",
    "text": "ANOVA Computations\n\nWe are finally done constructing our ANOVA table! As a reminder,\n\n\n\n\n\n\n\n\n\n\n\nSource\nSum of Squares\ndf\nMean Squares\nF\n\n\n\n\nTreatment\nSSTrt\ndfTrt\nMSTrt\nF0\n\n\nError\nSSE\ndfE\nMSE\n\n\n\nTotal\nSSTot\ndfTot"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-r-syntax",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#anova-r-syntax",
    "title": "One-Way Analysis of Variance",
    "section": "ANOVA: R Syntax",
    "text": "ANOVA: R Syntax\n\nWe can use the aov() and summary() functions.\n\n\nm &lt;- aov(continuous_variable ~ grouping_variable,\n         data = dataset_name)\nsummary(m)\n\n\nHowever, note that ANOVA is regression (and regression is ANOVA).\n\nWe can also use lm() to define the model and anova() to construct the ANOVA table.\n\n\n\nm &lt;- lm(continuous_variable ~ grouping_variable,\n         data = dataset_name)\nanova(m)"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental",
    "title": "One-Way Analysis of Variance",
    "section": "Example - Dental",
    "text": "Example - Dental\n\nProsthodontists specialize in the restoration of oral function, including the use of dental implants, veneers, dentures, and crowns. A researcher wanted to compare the shear bond strength of different repair kits for repairs of chipped porcelain veneer.\nHe randomly divided 20 porcelain specimens into four treatment groups: group 1 used the Cojet system, group 2 used the Silistor system, group 3 used the Cimara system, and group 4 used the Ceramic Repair system.\nAt the conclusion of the study, shear bond strength (in megapascals, MPa) was measured according to ISO 10477. The data are as follows,\n\n\nstrength &lt;- c(15.4, 12.9, 17.2, 16.6, 19.3,\n              17.2, 14.3, 17.6, 21.6, 17.5,\n               5.5,  7.7, 12.2, 11.4, 16.4,\n              11.0, 12.4, 13.5,  8.9,  8.1)\nsystem &lt;- c(rep(\"Cojet\",5), rep(\"Silistor\",5), rep(\"Cimara\",5), rep(\"Ceramic\",5))\ndata &lt;- tibble(system, strength)"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-1",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-1",
    "title": "One-Way Analysis of Variance",
    "section": "Example - Dental",
    "text": "Example - Dental\n\n\n\n  \n\n\n\n\nWhat is the continuous variable?\nWhat is the grouping variable?"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-2",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-2",
    "title": "One-Way Analysis of Variance",
    "section": "Example - Dental",
    "text": "Example - Dental\n\nOur first step will be to construct an ANOVA table for the data.\n\n\nm1 &lt;- aov(strength ~ system, data = data)\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nm2 &lt;- lm(strength ~ system, data = data)\nanova(m2)"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#hypothesis-testing",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#hypothesis-testing",
    "title": "One-Way Analysis of Variance",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nHypotheses\n\nH_0: \\ \\mu_1 = \\mu_2 = ... = \\mu_k\nH_1: at least one mean is different\n\nTest Statistic\n\nF_0 (pulled from the ANOVA table)\n\np-Value\n\np = P[F_0 \\ge F_{\\text{df}_{\\text{Trt}}, \\text{df}_{\\text{E}}}]\n\nRejection Region\n\nReject H_0 if p&lt;\\alpha."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-3",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-3",
    "title": "One-Way Analysis of Variance",
    "section": "Example - Dental",
    "text": "Example - Dental\n\nUsing the dental data:\n\n\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nDetermine if there is a difference in average strength between the groups. Test at the \\alpha=0.01 level."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-4",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example---dental-4",
    "title": "One-Way Analysis of Variance",
    "section": "Example - Dental",
    "text": "Example - Dental\n\nHypotheses\n\nH_0: \\ \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4\nH_1: at least one mean is different\n\nTest Statistic and p-Value\n\nF_0 = 7.545\np = 0.002\n\nRejection Region\n\nReject H_0 if p&lt;\\alpha; \\alpha = 0.01.\n\nConclusion/Interpretation\n\nReject H_0. There is sufficient evidence to suggest that there is a difference in average strength between the four groups."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing",
    "title": "One-Way Analysis of Variance",
    "section": "Introduction: Posthoc Testing",
    "text": "Introduction: Posthoc Testing\n\nToday we have introduced ANOVA. Recall the hypotheses,\n\nH_0: \\mu_1 = \\mu_2 = ... = \\mu_k\nH_1: at least one \\mu_i is different\n\nThe F test does not tell us which mean is different… only that a difference exists.\nIn theory, we could perform repeated t tests to determine pairwise differences.\n\nRecall that ANOVA is an extension of the t test… or that the t test is a special case of ANOVA.\nHowever, this will increase the Type I error rate (\\alpha)."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing-1",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing-1",
    "title": "One-Way Analysis of Variance",
    "section": "Introduction: Posthoc Testing",
    "text": "Introduction: Posthoc Testing\n\nRecall that the Type I error rate, \\alpha, is the probability of incorrectly rejecting H_0.\n\ni.e., we are saying there is a difference between the means when there is actually not a difference.\n\nSuppose we are comparing 5 groups.\n\nThis is 10 pairwise comparisons!!\n\n1-2, 1-3, 1-4, 1-5, 2-3, 2-4, 2-5, 3-4, 3-5, 4-5\n\nIf we perform repeated t tests under \\alpha=0.05, we are inflating the Type I error to 0.40! 😵"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing-2",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing-2",
    "title": "One-Way Analysis of Variance",
    "section": "Introduction: Posthoc Testing",
    "text": "Introduction: Posthoc Testing\n\nWhen performing posthoc comparisons, we can choose one of two paths:\n\nControl the Type I (familywise) error rate.\nDo not control the Type I error rate.\n\nNote that controlling the Type I error rate is more conservative than when we do not control it.\n\n“Conservative” = more difficult to reject.\n\nGenerally, statisticians:\n\ndo not control the Type I error rate if examining the results of pilot/preliminary studies that are exploring for general relationships.\ndo control the Type I error rate if examining the results of confirmatory studies and are attempting to confirm relationships observed in pilot/preliminary studies."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing-3",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#introduction-posthoc-testing-3",
    "title": "One-Way Analysis of Variance",
    "section": "Introduction: Posthoc Testing",
    "text": "Introduction: Posthoc Testing\n\nThe posthoc tests we will learn:\n\nTukey’s test\n\nPerforms all pairwise tests and controls the Type I error rate\n\nFisher’s least significant difference\n\nPerforms all pairwise tests but does not control the Type I error rate\n\nDunnett’s test\n\nCompares each group to a control group and controls the Type I error rate\n\n\nCaution: we should only perform posthoc tests if we have determined that a general difference exists!\n\ni.e., we rejected when looking at the F test in ANOVA"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#example",
    "title": "One-Way Analysis of Variance",
    "section": "Example",
    "text": "Example\n\nRecall the dental example from earlier,\n\n\nm1 &lt;- aov(strength ~ system, data = data)\nsummary(m1)\n\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nAre we justified in posthoc testing? (Recall: \\alpha=0.01)."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#tukeys-test",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#tukeys-test",
    "title": "One-Way Analysis of Variance",
    "section": "Tukey’s Test",
    "text": "Tukey’s Test\n\nTukey’s test allows us to do all pairwise comparisons while controlling \\alpha.\nThe underlying idea of the comparison:\n\nWe declare \\mu_i \\ne \\mu_j if |\\bar{y}_i - \\bar{y}_j| \\ge W, where  W = \\frac{q_{\\alpha}(k, \\text{df}_{\\text{E}})}{\\sqrt{2}} \\sqrt{\\text{MSE} \\left( \\frac{1}{n_i} + \\frac{1}{n_j} \\right)} \n\nq_{\\alpha}(k, \\text{df}_{\\text{E}}) is the critical value from the Studentized range distribution.\n\n\nWe will use the TukeyHSD() function.\n\nNote that this requires us to have created our model using the aov() function.\n\n\n\nm &lt;- aov(continuous_variable ~ grouping_variable, data = dataset_name)\nTukeyHSD(m)$grouping_variable"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#tukeys-test-1",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#tukeys-test-1",
    "title": "One-Way Analysis of Variance",
    "section": "Tukey’s Test",
    "text": "Tukey’s Test\n\nLet’s apply Tukey’s to the dental data.\n\n\nm &lt;- aov(strength ~ system, data = data)\nTukeyHSD(m, conf.level = 0.99)$system\n\n                  diff         lwr       upr       p adj\nCimara-Ceramic   -0.14 -7.04151507  6.761515 0.999845202\nCojet-Ceramic     5.50 -1.40151507 12.401515 0.044147158\nSilistor-Ceramic  6.86 -0.04151507 13.761515 0.010458208\nCojet-Cimara      5.64 -1.26151507 12.541515 0.038206781\nSilistor-Cimara   7.00  0.09848493 13.901515 0.008990873\nSilistor-Cojet    1.36 -5.54151507  8.261515 0.886304336\n\n\n\nWhich are significantly different at the \\alpha=0.01 level?"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#fishers-test",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#fishers-test",
    "title": "One-Way Analysis of Variance",
    "section": "Fisher’s Test",
    "text": "Fisher’s Test\n\nFisher’s allows us to test all pairwise comparisons but control the \\alpha.\nThe underlying idea of the comparison:\n\nWe declare \\mu_i \\ne \\mu_j if |\\bar{y}_i - \\bar{y}_j| \\ge \\text{LSD}, where  \\text{LSD} = t_{1-\\alpha/2, \\text{df}_\\text{E}} \\sqrt{\\text{MSE} \\left( \\frac{1}{n_i} + \\frac{1}{n_j} \\right)} \n\nWe will use the LSD.test() function from the agricolae package.\n\nNote that, like Tukey’s, this requires us to have created our model using the aov() function.\n\n\n\nlibrary(agricolae)\nresults &lt;- summary(m)\n(LSD.test(dataset_name$continuous_variable, # continuous outcome\n          dataset_name$grouping_variable, # grouping variable\n          results[[1]]$Df[2], # df_E\n          results[[1]]$`Mean Sq`[2], # MSE\n          alpha = alpha_level) # can omit if alpha = 0.05\n  )[5] # limit to only the pairwise comparison results"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#fishers-test-1",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#fishers-test-1",
    "title": "One-Way Analysis of Variance",
    "section": "Fisher’s Test",
    "text": "Fisher’s Test\n\nLet’s apply Fisher’s to the dental data.\n\n\nlibrary(agricolae)\nresults &lt;- summary(m)\nLSD.test(data$strength, \n         data$system, \n         results[[1]]$Df[2], \n         results[[1]]$`Mean Sq`[2],\n         alpha = 0.01)[5]\n\n$groups\n         data$strength groups\nSilistor         17.64      a\nCojet            16.28      a\nCeramic          10.78      b\nCimara           10.64      b\n\n\n\nWhich are significantly different at the \\alpha=0.01 level?"
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#dunnetts-test",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#dunnetts-test",
    "title": "One-Way Analysis of Variance",
    "section": "Dunnett’s Test",
    "text": "Dunnett’s Test\n\nDunnett’s test allows us to do all pairwise comparisons against only the control, while controlling \\alpha.\n\nThis has fewer comparisons than Tukey’s because we are not comparing non-control groups to one another.\ni.e., we are sharing the \\alpha between fewer comparisons now, which is preferred if we are not interested in the comparisons between non-control groups.\n\nThe underlying idea of the comparison:\n\nWe declare \\mu_i \\ne \\mu_j if |\\bar{y}_i - \\bar{y}_j| \\ge D, where  D = d_{\\alpha}(k-1, \\text{df}_{\\text{E}}) \\sqrt{\\text{MSE} \\left( \\frac{1}{n_i} + \\frac{1}{n_c} \\right)}, \n\nd_{\\alpha}(k-1, \\text{df}_{\\text{E}}) is the critical value from Dunnett’s table."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#dunnetts-test-1",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#dunnetts-test-1",
    "title": "One-Way Analysis of Variance",
    "section": "Dunnett’s Test",
    "text": "Dunnett’s Test\n\nWe will use the DunnettTest() function from the DescTools package to perform Dunnett’s test.\n\n\nlibrary(DescTools)\nDunnettTest(x=dataset_name$continuous_variable, \n            g=dataset_name$grouping_variable, \n            control = \"name of control group\")\n\n\nThe p-values are adjusted, so you can directly compare them to the specified \\alpha."
  },
  {
    "objectID": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#dunnetts-test-2",
    "href": "files/lectures/W06-L1-one-way-ANOVA-posthoc.html#dunnetts-test-2",
    "title": "One-Way Analysis of Variance",
    "section": "Dunnett’s Test",
    "text": "Dunnett’s Test\n\nLet’s apply Dunnett’s to the dental data.\n\nWe will treat “Ceramic” as the control group.\n\n\n\nlibrary(DescTools)\nDunnettTest(x=data$strength, \n            g=data$system, \n            control = \"Ceramic\")\n\n\n  Dunnett's test for comparing several treatments with a control :  \n    95% family-wise confidence level\n\n$Ceramic\n                  diff     lwr.ci    upr.ci   pval    \nCimara-Ceramic   -0.14 -5.0138317  4.733832 0.9997    \nCojet-Ceramic     5.50  0.6261683 10.373832 0.0259 *  \nSilistor-Ceramic  6.86  1.9861683 11.733832 0.0059 ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nWhich are significantly different at the \\alpha=0.01 level?"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#introduction",
    "href": "files/lectures/W04-L1-dependent-t.html#introduction",
    "title": "Dependent t-Tests",
    "section": "Introduction",
    "text": "Introduction\n\nIn the last lecture, we reviewed statistical inference on two independent means.\n\nCI for \\mu_1-\\mu_2\nHypothesis test for \\mu_1-\\mu_2 (two-sample t-test)\n\nToday, we will focus on drawing conclusions about two dependent means.\n\nCI for \\mu_d = \\mu_1-\\mu_2\nHypothesis test for \\mu_d = \\mu_1-\\mu_2 (paired t-test)"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#independent-vs.-dependent-data",
    "href": "files/lectures/W04-L1-dependent-t.html#independent-vs.-dependent-data",
    "title": "Dependent t-Tests",
    "section": "Independent vs. Dependent Data",
    "text": "Independent vs. Dependent Data\n\n\n\n\nIndependent data\n\n\nAn individual selected for one sample does not dictate which individual is to be in a second sample.\nIn the data, there is not a way to link the individuals in the sample.\n\n\n\n\n\n\n\n\nDependent data\n\n\nAn individual selected to be in one sample is used to determine the individual in the second sample.\nIn the data, there is a way to link the individuals in the sample.\n\n\n\n\n\nExamples:\n\nTwo sections of STA4173\nProject grades in one section of STA4173\nMale and female penguins\nPrices online vs. in store at Target"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#estimating-the-difference-between-two-dependent-means",
    "href": "files/lectures/W04-L1-dependent-t.html#estimating-the-difference-between-two-dependent-means",
    "title": "Dependent t-Tests",
    "section": "Estimating the Difference Between Two Dependent Means",
    "text": "Estimating the Difference Between Two Dependent Means\n\nWe are now interested in comparing two dependent groups.\nWe assume that the two groups come from the same population and are going to examine the difference,\n\n\nd = y_{i, 1} - y_{i, 2}\n\n\nAfter drawing samples, we have the following,\n\n\\bar{d} estimates \\mu_d,\ns^2_d estimates \\sigma^2_d, and\nn is the sample size."
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#ci-for-the-difference-between-two-dependent-means",
    "href": "files/lectures/W04-L1-dependent-t.html#ci-for-the-difference-between-two-dependent-means",
    "title": "Dependent t-Tests",
    "section": "CI for the Difference Between Two Dependent Means",
    "text": "CI for the Difference Between Two Dependent Means\n\n\n\n\n\\mathbf{(1-\\boldsymbol\\alpha)100\\%} confidence interval for \\mathbf{\\boldsymbol\\mu_d}\n\n\n \\bar{d} \\pm t_{\\alpha/2} \\frac{s_d}{\\sqrt{n}} \n\nwhere t_{\\alpha/2} has n-1 degrees of freedom.\nTo construct this interval, we require either:\n\nthe differences to be normally distributed or\nthe sample size is sufficiently large (n \\ge 30)\n\n\n\n\n\n\n\nR syntax:\n\n\nt.test(dataset_name$variable1_name,\n       dataset_name$variable2_name, \n       paired = TRUE, \n       conf.level = confidence_level)"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#ci-for-the-difference-between-two-dependent-means-1",
    "href": "files/lectures/W04-L1-dependent-t.html#ci-for-the-difference-between-two-dependent-means-1",
    "title": "Dependent t-Tests",
    "section": "CI for the Difference Between Two Dependent Means",
    "text": "CI for the Difference Between Two Dependent Means\n\nInsurance adjusters are concerned about the high estimates they are receiving for auto repairs from garage I compared to garage II.\n15 cars were taken to both garages for separate estimates of repair costs.\n\n\nlibrary(tidyverse)\ngarage &lt;- tibble(g1 = c(17.6, 20.2, 19.5, 11.3, 13.0, \n                        16.3, 15.3, 16.2, 12.2, 14.8,\n                        21.3, 22.1, 16.9, 17.6, 18.4), \n                 g2 = c(17.3, 19.1, 18.4, 11.5, 12.7, \n                        15.8, 14.9, 15.3, 12.0, 14.2, \n                        21.0, 21.0, 16.1, 16.7, 17.5))\n\n\nConstruct the 95% confidence interval for the average difference between the two garages.\nRemember the R syntax:\n\n\nt.test(dataset_name$variable1_name,\n       dataset_name$variable2_name, \n       paired = TRUE, \n       conf.level = confidence_level)"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#ci-for-the-difference-between-two-dependent-means-2",
    "href": "files/lectures/W04-L1-dependent-t.html#ci-for-the-difference-between-two-dependent-means-2",
    "title": "Dependent t-Tests",
    "section": "CI for the Difference Between Two Dependent Means",
    "text": "CI for the Difference Between Two Dependent Means\n\nt.test(garage$g1, \n       garage$g2, \n       paired = TRUE, \n       conf.level = 0.95)\n\n\n    Paired t-test\n\ndata:  garage$g1 and garage$g2\nt = 6.0234, df = 14, p-value = 3.126e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.3949412 0.8317254\nsample estimates:\nmean difference \n      0.6133333 \n\n\n\nThe 95% CI for \\mu_d, where d = x_{\\text{I}} - x_{\\text{II}} is (0.39, 0.83).\nFrom the problem statement:\n\nInsurance adjusters are concerned about the high estimates they are receiving for auto repairs from garage I compared to garage II.\n\nCan we say that estimates from garage I are higher than those from garage II?"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#paired-t-test-for-two-dependent-means",
    "href": "files/lectures/W04-L1-dependent-t.html#paired-t-test-for-two-dependent-means",
    "title": "Dependent t-Tests",
    "section": "Paired t-Test for Two Dependent Means",
    "text": "Paired t-Test for Two Dependent Means\nHypotheses\n\nH_0: \\mu_d = \\mu_0 | H_0: \\mu_d \\le \\mu_0 | H_0: \\mu_d \\ge \\mu_0\nH_1: \\mu_d \\ne \\mu_0 | H_1: \\mu_d &gt; \\mu_0 | H_1: \\mu_d &lt; \\mu_0\n\nTest Statistic & p-Value\n\nt_0 = \\frac{\\bar{d}-\\mu_0}{\\frac{s_d}{\\sqrt{n}}}\np = 2 P[t \\ge |t_0|] | p = P[t \\ge |t_0|] | p = P[t \\le |t_0|]\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha.\n\nConclusion/Interpretation\n\n[Reject or fail to reject] H_0.\nThere [is or is not] sufficient evidence to suggest [alternative hypothesis in words]."
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#paired-t-test",
    "href": "files/lectures/W04-L1-dependent-t.html#paired-t-test",
    "title": "Dependent t-Tests",
    "section": "Paired t-Test",
    "text": "Paired t-Test\n\nR syntax:\n\n\nt.test(dataset_name$variable1_name, \n       dataset_name$variable2_name, \n       paired = TRUE, \n       mu = hypothesized_difference,\n       alternative = \"alternative\")\n\n\nImportant!!\n\nWe are estimating \\mu_1 - \\mu_2, but R is going to subtract in the order we state in the t.test() function."
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#paired-t-test-example",
    "href": "files/lectures/W04-L1-dependent-t.html#paired-t-test-example",
    "title": "Dependent t-Tests",
    "section": "Paired t-Test: Example",
    "text": "Paired t-Test: Example\n\nLet’s now formally determine if garage I’s estimates are higher than garage II’s. Test at the \\alpha=0.05 level.\nRecall the data,\n\n\ngarage &lt;- tibble(g1 = c(17.6, 20.2, 19.5, 11.3, 13.0, \n                        16.3, 15.3, 16.2, 12.2, 14.8,\n                        21.3, 22.1, 16.9, 17.6, 18.4), \n                 g2 = c(17.3, 19.1, 18.4, 11.5, 12.7, \n                        15.8, 14.9, 15.3, 12.0, 14.2, \n                        21.0, 21.0, 16.1, 16.7, 17.5))\n\n\nand the R syntax:\n\n\nt.test(dataset_name$variable1_name, \n       dataset_name$variable2_name, \n       paired = TRUE, \n       mu = hypothesized_difference,\n       alternative = \"alternative\")"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#paired-t-test-example-1",
    "href": "files/lectures/W04-L1-dependent-t.html#paired-t-test-example-1",
    "title": "Dependent t-Tests",
    "section": "Paired t-Test: Example",
    "text": "Paired t-Test: Example\n\nt.test(garage$g1, \n       garage$g2,\n       paired = TRUE,\n       mu = 0,\n       alternative = \"greater\")\n\n\n    Paired t-test\n\ndata:  garage$g1 and garage$g2\nt = 6.0234, df = 14, p-value = 1.563e-05\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 0.4339886       Inf\nsample estimates:\nmean difference \n      0.6133333 \n\n\n\nAre the estimates from garage I significantly higher than those from garage II?"
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#paired-t-test-example-2",
    "href": "files/lectures/W04-L1-dependent-t.html#paired-t-test-example-2",
    "title": "Dependent t-Tests",
    "section": "Paired t-Test: Example",
    "text": "Paired t-Test: Example\nHypotheses\n\nH_0: \\ \\mu_{\\text{I}} \\le \\mu_{\\text{II}} OR \\mu_{d} \\le 0, where \\mu_d = \\mu_{\\text{I}} - \\mu_{\\text{II}}\nH_1: \\ \\mu_{\\text{I}} &gt; \\mu_{\\text{II}} OR \\mu_{d} &gt; 0\n\nTest Statistic and p-Value\n\nt_0 = 6.023\np &lt; 0.001\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha; \\alpha = 0.05.\n\nConclusion/Interpretation\n\nReject H_0.\nThere is sufficient evidence to suggest the estimates at garage I are higher than that of garage II."
  },
  {
    "objectID": "files/lectures/W04-L1-dependent-t.html#wrap-up",
    "href": "files/lectures/W04-L1-dependent-t.html#wrap-up",
    "title": "Dependent t-Tests",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nToday we reviewed the dependent t-test.\n\nConfidence intervals\nHypothesis testing\n\nNext lectures:\n\nAssumptions on t-tests.\nWilcoxon rank sum\nWilcoxon signed rank"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#introduction",
    "href": "files/lectures/W01-L1-review-of-estimation.html#introduction",
    "title": "Review of Statistical Estimation",
    "section": "Introduction",
    "text": "Introduction\n\nIn this lecture, we will review estimation\n\nContinuous variables\n\nMean\nMedian\nPercentiles / quartiles\nVariance and standard deviation\nInterquartile range\n\nCategorical variables\n\nCount\nPercentage\n\n\nWe will also discuss exploring data graphically"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#r-introduction",
    "href": "files/lectures/W01-L1-review-of-estimation.html#r-introduction",
    "title": "Review of Statistical Estimation",
    "section": "R: Introduction",
    "text": "R: Introduction\n\nIn this course, we will review formulas, but we will use R for computational purposes\n\nRemember to refer to the lecture notes for specific code needed\nCode is also available on this course’s GitHub repository\n\nYou can install R and RStudio if you wish; both are free.\n\nWe have access to the Posit Workbench (“the server”) through HMCSE.\n\nI know that this is probably the first time you are seeing R (or any sort of programming).\n\nThat is why we have “R lab” time built in to our course.\nRemember that I am not looking for perfection, but instead for competency."
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#todays-data-palmer-penguins",
    "href": "files/lectures/W01-L1-review-of-estimation.html#todays-data-palmer-penguins",
    "title": "Review of Statistical Estimation",
    "section": "Today’s Data: Palmer Penguins",
    "text": "Today’s Data: Palmer Penguins\n\nToday we will be demonstrating the basics using the Palmer Penguins dataset, available through R.\n\n\npenguins &lt;- palmerpenguins::penguins"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#types-of-variables",
    "href": "files/lectures/W01-L1-review-of-estimation.html#types-of-variables",
    "title": "Review of Statistical Estimation",
    "section": "Types of Variables",
    "text": "Types of Variables\n\n\n\n\n\n\nContinuous Variables\n\n\nA continuous variable is a variable that can has an infinite set of possible values.\n\n\n\n\nBetween any two possible values, there are an infinite number of possible values.\nThese typically arise from measurement. (Height, weight, etc.)\n\n\n\n\n\n\n\nDiscrete Variables\n\n\nA discrete variable is a variable that can only take on a finite set of possible values.\n\n\n\n\nThe possible values can usually be listed.\nThese typically arise from categorizing (work vs. home) or counting."
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#types-of-variables-1",
    "href": "files/lectures/W01-L1-review-of-estimation.html#types-of-variables-1",
    "title": "Review of Statistical Estimation",
    "section": "Types of Variables",
    "text": "Types of Variables"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#types-of-continuous-variables",
    "href": "files/lectures/W01-L1-review-of-estimation.html#types-of-continuous-variables",
    "title": "Review of Statistical Estimation",
    "section": "Types of Continuous Variables",
    "text": "Types of Continuous Variables\n\n\n\n\n\n\nRatio Variables\n\n\nA ratio variable is a variable that has a meaningful zero point, allowing comparisons of magnitude.\n\n\n\n\nTrue zero point indicates the absence of the quantity being measured.\nAll arithmetic operations (addition, subtraction, multiplication, division) are meaningful.\n\n\n\n\n\n\n\nInterval Variables\n\n\nAn interval variable has an arbitrary zero point and differences between values are meaningful.\n\n\n\n\nThe zero point does not indicate a true absence.\nA 1 unit difference always represents the same amount."
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#types-of-discrete-variables",
    "href": "files/lectures/W01-L1-review-of-estimation.html#types-of-discrete-variables",
    "title": "Review of Statistical Estimation",
    "section": "Types of Discrete Variables",
    "text": "Types of Discrete Variables\n\n\n\n\n\n\nOrdinal Variables\n\n\nAn ordinal variable has a meaningful order of responses; the exact differences between responses are not necessarily equal.\n\n\n\n\nWe understand which value is “greater” or “less,” but not by how much.\nArithmetic is not meaningful.\n\n\n\n\n\n\n\nNominal Variables\n\n\nA nominal variable has is no intrinsic order among the categories.\n\n\n\n\nCategories are used merely as labels or names.\nNo arithmetic or ordering operations are meaningful."
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-mean",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-mean",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Centrality: Mean",
    "text": "Measures of Centrality: Mean\n\n\n\n\n\n\nSample Mean\n\n\nThe sample mean provides a single number that can represent a “typical” or central value in your data.\n\n\\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}\n\n\n\n\n\nR syntax:\n\n\ndataset_name %&gt;% summarize(mean(variable_name, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-mean-1",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-mean-1",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Centrality: Mean",
    "text": "Measures of Centrality: Mean\n\nLet’s find the average weight (body_mass_g) of the penguins.\n\n\npenguins %&gt;% summarize(mean(body_mass_g, na.rm = TRUE))\n\n\n  \n\n\n\n\nLet’s find the average flipper length (flipper_length_mm) of the penguins.\n\n\npenguins %&gt;% summarize(mean(flipper_length_mm, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-median",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-median",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Centrality: Median",
    "text": "Measures of Centrality: Median\n\n\n\n\n\n\nSample Median\n\n\nThe sample median is the midpoint of a distribution, the number such that half the observations are smaller and the other half are larger.\n\nIf n is odd, the median is the single middle value.\nIf n is even, the median is the average of the two middle values.\n\n\n\n\n\nR syntax:\n\n\ndataset_name %&gt;% summarize(median(variable_name, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-median-1",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-centrality-median-1",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Centrality: Median",
    "text": "Measures of Centrality: Median\n\nLet’s find the median weight (body_mass_g) of the penguins.\n\n\npenguins %&gt;% summarize(median(body_mass_g, na.rm = TRUE))\n\n\n  \n\n\n\n\nLet’s find the median flipper length (flipper_length_mm) of the penguins.\n\n\npenguins %&gt;% summarize(median(flipper_length_mm, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-variance-and-standard-deviation",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-variance-and-standard-deviation",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Spread: Variance and Standard Deviation",
    "text": "Measures of Spread: Variance and Standard Deviation\n\n\n\n\n\n\nSample Variance\n\n\nThe sample variance measures how “widely spread” the data points are around the mean.\ns^2 = \\frac{\\sum_{i=1}^n x_i^2 - \\frac{(\\sum_{i=1}^n x_i)^2}{n}}{n-1}\n\n\n\n\nWhen we have a mound-shaped and symmetric distribution, most observations will fall within 2 standard deviations of the mean.\nVariance results in units2, which typically does not make sense.\n\n\n\n\n\n\n\nSample Standard Deviation\n\n\nThe sample standard deviation also measures how “widely spread” the data points are around the mean.\ns = \\sqrt{s^2}\n\n\n\n\nStandard deviation is the square root of the variance, measuring spread in the original units of the data.\nR syntax:\n\n\ndataset_name %&gt;% summarize(var(variable_name, na.rm = TRUE), \n                           sd(variable_name, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-variance-and-standard-deviation-1",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-variance-and-standard-deviation-1",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Spread: Variance and Standard Deviation",
    "text": "Measures of Spread: Variance and Standard Deviation\n\nLet’s find the variance and standard deviation of the weight (body_mass_g) of the penguins.\n\n\npenguins %&gt;% summarize(var(body_mass_g, na.rm = TRUE),\n                       sd(body_mass_g, na.rm = TRUE))\n\n\n  \n\n\n\n\nLet’s find the variance and standard deviation of the flipper length (flipper_length_mm) of the penguins.\n\n\npenguins %&gt;% summarize(var(flipper_length_mm, na.rm = TRUE),\n                       sd(flipper_length_mm, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-interquartile-range",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-interquartile-range",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Spread: Interquartile Range",
    "text": "Measures of Spread: Interquartile Range\n\n\n\n\n\n\nSample Interquartile Range\n\n\nThe sample interquartile range measures the spread of the middle 50% of data.\n\\text{IQR} = P_{75}-P_{25}\n\n\n\n\nR syntax:\n\n\ndataset_name %&gt;% summarize(IQR(variable_name))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-interquartile-range-1",
    "href": "files/lectures/W01-L1-review-of-estimation.html#measures-of-spread-interquartile-range-1",
    "title": "Review of Statistical Estimation",
    "section": "Measures of Spread: Interquartile Range",
    "text": "Measures of Spread: Interquartile Range\n\nLet’s find the IQR of the weight (body_mass_g) of the penguins.\n\n\npenguins %&gt;% summarize(IQR(body_mass_g, na.rm = TRUE))\n\n\n  \n\n\n\n\nLet’s find the IQR of the flipper length (flipper_length_mm) of the penguins.\n\n\npenguins %&gt;% summarize(IQR(flipper_length_mm, na.rm = TRUE))"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#mean-standard-deviation-vs.-median-iqr",
    "href": "files/lectures/W01-L1-review-of-estimation.html#mean-standard-deviation-vs.-median-iqr",
    "title": "Review of Statistical Estimation",
    "section": "Mean & Standard Deviation vs. Median & IQR",
    "text": "Mean & Standard Deviation vs. Median & IQR\n\nWhen should we use the mean vs. the median to describe the center of the distribution?\n\nMound-shaped and symmetric \\to \\bar{x} & s.\nNot mound-shaped and symmetric \\to M & \\text{IQR}.\n\n… How do we know the shape of the distribution?\nWe will explore histograms."
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms",
    "text": "Graphs: Histograms"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-1",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-1",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms",
    "text": "Graphs: Histograms"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-2",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-2",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms",
    "text": "Graphs: Histograms"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-3",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-3",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms",
    "text": "Graphs: Histograms"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-r-code",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-r-code",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms (R code)",
    "text": "Graphs: Histograms (R code)\n\nWe are using the ggplot2 package for graphing.\n\nIt will always start with ggplot().\nWe will then layer elements on top.\n\nR syntax:\n\n\ndataset_name %&gt;% \n  ggplot(aes(x=variable_name)) + \n  geom_histogram()"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-4",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-4",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms",
    "text": "Graphs: Histograms\n\nLet’s look at the histogram of penguin weight (body_mass_g):\n\n\n\npenguins %&gt;% \n  ggplot(aes(x=body_mass_g)) + \n  geom_histogram()"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-5",
    "href": "files/lectures/W01-L1-review-of-estimation.html#graphs-histograms-5",
    "title": "Review of Statistical Estimation",
    "section": "Graphs: Histograms",
    "text": "Graphs: Histograms\n\nLet’s look at the histogram of penguin weight (body_mass_g):\n\n\n\npenguins %&gt;% \n  ggplot(aes(x=body_mass_g)) + \n  geom_histogram() +\n  labs(x = \"Body Mass (g)\",\n       y = \"Number of Penguins\",\n       title = \"Penguin Weight Distribution\") +\n  theme_bw()"
  },
  {
    "objectID": "files/lectures/W01-L1-review-of-estimation.html#wrap-up",
    "href": "files/lectures/W01-L1-review-of-estimation.html#wrap-up",
    "title": "Review of Statistical Estimation",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nToday we reviewed estimation.\nNext week, we will review statistical inference.\n\nConfidence intervals\nHypothesis testing\n\nGet to know you quiz - complete with RStudio.\n\n.qmd \\to Quarto\n.R \\to R script\n\nJoin the Discord server!\n\nIf you are already a Discord user, this is a friendly reminder that you can change your display name…"
  },
  {
    "objectID": "files/assignments/Assignment0.html",
    "href": "files/assignments/Assignment0.html",
    "title": "Introductions",
    "section": "",
    "text": "What is your name as it appears on my roster in Classmate? (We are using this assignment for attendance verification.)\nHow is your name pronounced?\nIs there another name you prefer to go by?\nWhat are your pronouns?\nWhat is your major(s) and minor(s)?\nWhat statistics courses have you taken previously?\nAre you familiar with statistical programming? (e.g., R, python, SAS, etc.)\nDo you have any questions or concerns about this course? If so, please list them and we will respond when we grade this assignment.\nWhat interests do you have, outside of school and work?\nWhat are three of your favorite things?\nIf you were independently wealthy, what would you do with your time?"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "<b>STA4173 - Biostatistics - Spring 2025</b>",
    "section": "",
    "text": "Tentative Schedule\n\n\n\n\n\n\n\n\n\nDay\nTopic\nSlides\nIn Class\n\n\n\n\nR 01/09\nReview of estimation\n \n \n\n\nT 01/14\nIndependent t test\n \n\n\n\nSnow & Illness\ndependent t-test\n \n\n\n\n\nt-test assumptions\n \n\n\n\n\nWilcoxon rank sum (independent)\n \n\n\n\n\nWilcoxon signed rank (dependent)\n \n\n\n\nT 02/04\nAssignment 1\n\n\n\n\nR 02/06\nAssignment 1\n\n\n\n\nT 02/11\nProject: planning period\n\n\n\n\nR 02/13\nOne-way ANOVA and posthoc\n \n\n\n\nT 02/18\nANOVA assumptions & Kruskal-Wallis\n\n\n\n\nR 02/20\nTwo-Way ANOVA\n\n\n\n\nT 02/25\nSimple linear regression and correlation\n\n\n\n\nR 02/27\nProject: planning meeting\n\n\n\n\nT 03/04\nMultiple regression\n\n\n\n\nR 03/06\nCategorical analysis\n\n\n\n\nT 03/11\nLogistic regression\n\n\n\n\nR 03/13\nProject: planning\n\n\n\n\nT 03/18\nSpring Break!\n\n\n\n\nR 03/20\nSpring Break!\n\n\n\n\nT 03/25\nProject: analysis\n\n\n\n\nR 03/27\nOUR: What is a Poster?\n\n\n\n\nT 04/01\nProject: analysis\n\n\n\n\nR 04/03\nProject: summary\n\n\n\n\nT 04/08\nProject: poster draft\n\n\n\n\nR 04/10\nIndividual group meetings with Dr. Seals\n\n\n\n\nT 04/15\nPoster presentation practice\n\n\n\n\nR 04/17\nOUR Symposium\n\n\n\n\nT 04/22\nCatch up!\n\n\n\n\nR 04/24\nProject: reflections"
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#introduction",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#introduction",
    "title": "Wilcoxon Rank Sum",
    "section": "Introduction",
    "text": "Introduction\n\nWe last discussed assumptions on t-tests\n\nDependent / paired t-test: normality\nIndependent two-sample t-test: normality and variance\n\nIf we break the normality assumption, we must look to nonparametric methods."
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#introduction-1",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#introduction-1",
    "title": "Wilcoxon Rank Sum",
    "section": "Introduction",
    "text": "Introduction\n\nThe t-tests we have already learned are considered parametric methods.\n\nThere is a distributional assumption on the test.\n\nNonparametric methods do not have distributional assumptions.\n\nWe typically transform the data to their ranks and then perform calculations.\n\nWhy don’t we always use nonparametric methods?\n\nThey are often less efficient: a larger sample size is required to achieve the same probability of a Type I error.\nThey discard useful information :("
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#ranking-data",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#ranking-data",
    "title": "Wilcoxon Rank Sum",
    "section": "Ranking Data",
    "text": "Ranking Data\n\nIn the nonparametric tests we will be learning, the data will be ranked.\nLet us first consider a simple example, x: \\ 1, 7, 10, 2, 6, 8\nOur first step is to reorder the data:x: \\ 1, 2, 6, 7, 8, 10\nThen, we replace with the ranks:R: \\ 1, 2, 3, 4, 5, 6"
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#ranking-data-1",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#ranking-data-1",
    "title": "Wilcoxon Rank Sum",
    "section": "Ranking Data",
    "text": "Ranking Data\n\nWhat if all data values are not unique?\n\nWe will assign the average ranks.\n\nFor example, x: \\ 9, 8, 8, 0, 3, 4, 4, 8\nLet’s reorder:x: \\ 0, 3, 4, 4, 8, 8, 8, 9\nRank ignoring ties:R: \\ 1, 2, 3, 4, 5, 6, 7, 8\nNow, the final rank:R: \\ 1, 2, 3.5, 3.5, 6, 6, 6, 8"
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum",
    "title": "Wilcoxon Rank Sum",
    "section": "Wilcoxon Rank Sum",
    "text": "Wilcoxon Rank Sum\nHypotheses\n\nH_0: M_1 - M_2 = M_0 | H_0: M_1 - M_2 \\le M_0 | H_0: M_1 - M_2 \\ge M_0\nH_1: M_1 - M_2 \\ne M_0 | H_1: M_1 - M_2 &gt; M_0 | H_1: M_1 - M_2 &lt; M_0\n\nTest Statistic & p-Value\n\nT = \\sum R_{\\text{sample 1}} - \\frac{n_1(n_1+1)}{2}\np = (calculated by R :))\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha.\n\nConclusion/Interpretation\n\n[Reject or fail to reject] H_0.\nThere [is or is not] sufficient evidence to suggest [alternative hypothesis in words]."
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-1",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-1",
    "title": "Wilcoxon Rank Sum",
    "section": "Wilcoxon Rank Sum",
    "text": "Wilcoxon Rank Sum\n\nWe will use the wilcox.test() function to perform the test,\n\n\nwilcox.test(continuous_variable ~ grouping_variable,\n            data = dataset_name,\n            alternative = \"alternative\",\n            mu = hypothesized_value,\n            exact = FALSE)\n\n\nLike before, R will use the group that is “first” in the grouping variable.\n\n“First” is in terms of numeric or alphabetical."
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-2",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-2",
    "title": "Wilcoxon Rank Sum",
    "section": "Wilcoxon Rank Sum",
    "text": "Wilcoxon Rank Sum\n\nWhen exposed to an infection, a person typically develops antibodies. The extent to which the antibodies respond can be measured by looking at a person’s titer, which is a measure of the number of antibodies present. The higher the titer is, the more antibodies that are present.\nThe following data represent the titers of 11 ill people and 11 healthy people exposed to the tularemia virus in Vermont.\nIs the level of titer in the ill group greater than the level of titer in the healthy group? Use the \\alpha = 0.10 level of significance.\n\n\ntiter_levels &lt;- tibble(level = c(640, 160, 1280, 320, 80, 640, 640, 160, 1280, 640, 160, \n                                  10, 320, 160, 160, 320, 320, 10, 320, 320, 80, 640),\n                       group = c(rep(\"ill\",11), rep(\"healthy\",11)))\n\n\nRecall the R syntax,\n\n\nwilcox.test(continuous_variable ~ grouping_variable,\n            data = dataset_name,\n            alternative = \"alternative\",\n            mu = hypothesized_value,\n            exact = FALSE)"
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-3",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-3",
    "title": "Wilcoxon Rank Sum",
    "section": "Wilcoxon Rank Sum",
    "text": "Wilcoxon Rank Sum\n\nIs the level of titer in the ill group greater than the level of titer in the healthy group?\n\n\nwilcox.test(level ~ group, \n            data = titer_levels,\n            alternative = \"less\",\n            exact = FALSE)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  level by group\nW = 35, p-value = 0.04657\nalternative hypothesis: true location shift is less than 0"
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-4",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wilcoxon-rank-sum-4",
    "title": "Wilcoxon Rank Sum",
    "section": "Wilcoxon Rank Sum",
    "text": "Wilcoxon Rank Sum\nHypotheses\n\nH_0: \\ M_{\\text{ill}} \\le M_{\\text{healthy}}\nH_1: \\ M_{\\text{ill}} &gt; M_{\\text{healthy}}\n\nTest Statistic and p-Value\n\nW_0 = 35\np = 0.047\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha; \\alpha = 0.10.\n\nConclusion/Interpretation\n\nReject H_0.\nThere is sufficient evidence to suggest that the level of titer in the ill group is greater than the level of titer in the healthy group."
  },
  {
    "objectID": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wrap-up",
    "href": "files/lectures/W04-L3-Wilcoxon-rank-sum.html#wrap-up",
    "title": "Wilcoxon Rank Sum",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nToday we reviewed the Wilcoxon rank sum test.\n\nNonparametric alternative to the two-sample t-test.\n\nNext lecture:\n\nWilcoxon signed rank"
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#introduction-assumptions",
    "href": "files/lectures/W04-L2-assumptions.html#introduction-assumptions",
    "title": "t-Test Assumptions",
    "section": "Introduction: Assumptions",
    "text": "Introduction: Assumptions\n\nWe have now learned one- and two-sample t-tests.\nRecall, when we have two samples, they can be independent samples or dependent samples.\n\nIndependent samples: two-sample t-test\nDependent samples: paired t-test (one-sample t-test on difference)\n\nToday we will discuss how to assess the assumptions on t-tests."
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-set-up",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-set-up",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Set Up",
    "text": "Normality Assumption: Set Up\n\nAll t-tests assume approximate normality of the data.\n\nIn the case of one-sample t-tests, the measure of interest must somewhat follow a normal distribution.\nIn the case of two-sample t-tests, the measure of interest in each group must somewhat follow a normal distribution.\n\nNote that a paired t-test is technically a one-sample t-test, so we will examine normality of the difference."
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-set-up-1",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-set-up-1",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Set Up",
    "text": "Normality Assumption: Set Up\n\nThere are formal tests for normality (see article here), however, we will not use them.\n\nTests for normality are not well-endorsed by statisticians.\n\nInstead, we will assess normality using a quantile-quantile (q-q) plot.\n\nThis is a scatterplot that will form a 45° line if the assumed distribution is correct.\nHere is more information about q-q plots.\n\nWe will create q-q plots for:\n\nThe measurements in the case of the one-sample t-test.\nThe measurements from each group in the case of the two-sample t-test.\nThe difference between the groups in the case of the paired t-test."
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-r-syntax",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-r-syntax",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: R Syntax",
    "text": "Normality Assumption: R Syntax\n\nWe will assess the normality assumption graphically using a q-q plot\nA package was written by a former student, classpackage.\n\nIf you are working on the server, the package is already installed.\nIf you are not working on the server, please ask me for the code needed to install."
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-independent-data---r-syntax",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-independent-data---r-syntax",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Independent Data - R Syntax",
    "text": "Normality Assumption: Independent Data - R Syntax\n\nOnce installed, we call the package,\n\n\nlibrary(classpackage)\n\n\nWhile there are several functions in this package, we are currently interested in the independent_qq_plot() function.\n\n\ndataset_name %&gt;% independent_qq_plot(variable = \"continuous variable\",\n                                     grouping_variable = \"grouping variable\")\n\n\nThis will provide the the q-q plot for the two-sample t-test (i.e., for independent data)."
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-independent-data---example",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-independent-data---example",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Independent Data - Example",
    "text": "Normality Assumption: Independent Data - Example\n\nRecall the penguin example for the two-sample t-test.\n\nIs the body mass different for males and females?\n\n\n\npenguins &lt;- palmerpenguins::penguins\nhead(penguins, n=3)\n\n\n  \n\n\n\n\nRequesting the q-q plot,\n\n\npenguins %&gt;% independent_qq_plot(variable = \"body_mass_g\",\n                                 grouping_variable = \"sex\")"
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-independent-data---example-1",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-independent-data---example-1",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Independent Data - Example",
    "text": "Normality Assumption: Independent Data - Example"
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-dependent-data---r-syntax",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-dependent-data---r-syntax",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Dependent Data - R Syntax",
    "text": "Normality Assumption: Dependent Data - R Syntax\n\nWhile there are several functions in the classpackage package, we are now interested in the dependent_qq_plot() function.\n\n\nwide_data %&gt;% dependent_qq_plot(variable = \"Display Name of Continuous Variable\",\n                                grouping_variable = \" \", # do not edit this line\n                                first_group = \"first_variable\", # first column for comparison\n                                second_group = \"second_variable\") # second column for comparison\n\n\nThis will provide the the q-q plot for the paired t-test (i.e., for dependent data)."
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-repair-estimates",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-repair-estimates",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Repair Estimates",
    "text": "Normality Assumption: Repair Estimates\n\nRecall the repair estimate example for the dependent t-test.\n\n\ngarage &lt;- tibble(g1 = c(17.6, 20.2, 19.5, 11.3, 13.0, \n                        16.3, 15.3, 16.2, 12.2, 14.8,\n                        21.3, 22.1, 16.9, 17.6, 18.4), \n                 g2 = c(17.3, 19.1, 18.4, 11.5, 12.7, \n                        15.8, 14.9, 15.3, 12.0, 14.2, \n                        21.0, 21.0, 16.1, 16.7, 17.5))\n\n\nRequesting the q-q plot,\n\n\ngarage %&gt;% dependent_qq_plot(variable = \"estimate\",\n                             grouping_variable = \"garage\",\n                             first_group = \"g1\",\n                             second_group = \"g2\")"
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#normality-assumption-repair-estimates-1",
    "href": "files/lectures/W04-L2-assumptions.html#normality-assumption-repair-estimates-1",
    "title": "t-Test Assumptions",
    "section": "Normality Assumption: Repair Estimates",
    "text": "Normality Assumption: Repair Estimates"
  },
  {
    "objectID": "files/lectures/W04-L2-assumptions.html#wrap-up",
    "href": "files/lectures/W04-L2-assumptions.html#wrap-up",
    "title": "t-Test Assumptions",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nImportant note!!\n\nI do not expect you to agree with my assessment of q-q plots!\nWhat I do expect is that you know what to do after making your assessment.\n\nNext up:\n\nWhat happens if we do not meet the assumption for a t-test….?"
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#introduction",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#introduction",
    "title": "Wilcoxon Signed Rank",
    "section": "Introduction",
    "text": "Introduction\n\nToday we have discussed that we turn to nonparametric tests when we do not meet distributional assumptions for t-tests.\nIf we do not meet the normality assumption for the paired t-test, we turn to the Wilcoxon signed rank.\nLike in the dependent t-test, we will analyze the difference between two values.\nLike in the Wilcoxon rank sum, we will be analyzing ranks."
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank",
    "title": "Wilcoxon Signed Rank",
    "section": "Wilcoxon Signed Rank",
    "text": "Wilcoxon Signed Rank\n\nBefore ranking, we will find the difference between the paired observations and eliminate any 0 differences.\n\nNote 1: elimniating 0 differences is the big difference between the other tests!\nNote 2: because we are eliminating 0 differences, this means that our sample size will update to the number of pairs with a non-0 difference.\n\nWhen ranking, we the differences are ranked based on the absolute value of the difference.\nWe also keep the sign of the difference.\n\nWe will have positive ranks and negative ranks.\n\n\n\n\n\nX\nY\nD\n|D|\nRank\n\n\n\n\n5\n8\n-3\n3\n- 1.5\n\n\n8\n5\n3\n3\n+ 1.5\n\n\n4\n4\n0\n0\n———"
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-1",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-1",
    "title": "Wilcoxon Signed Rank",
    "section": "Wilcoxon Signed Rank",
    "text": "Wilcoxon Signed Rank\nHypotheses\n\nH_0: M_d = M_0 | H_0: M_d \\le M_0 | H_0: M_d \\ge M_0\nH_1: M_d \\ne M_0 | H_1: M_d &gt; M_0 | H_1: M_d &lt; M_0\n\nTest Statistic & p-Value\n\nT_0 = \\min(T+,|T_-|) if two-tailed, T_0 = T_+ if left-tailed, and T_0 = |T_-| if right-tailed.\np = (calculated by R :))\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha.\n\nConclusion/Interpretation\n\n[Reject or fail to reject] H_0.\nThere [is or is not] sufficient evidence to suggest [alternative hypothesis in words]."
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-2",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-2",
    "title": "Wilcoxon Signed Rank",
    "section": "Wilcoxon Signed Rank",
    "text": "Wilcoxon Signed Rank\n\nWe will again use the wilcox.test() function to perform the test,\n\n\nwilcox.test(dataset$variable1, dataset$variable2,\n       alternative = \"alternative\",\n       mu = hypothesized_value,\n       paired = TRUE,\n       exact = FALSE)"
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-3",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-3",
    "title": "Wilcoxon Signed Rank",
    "section": "Wilcoxon Signed Rank",
    "text": "Wilcoxon Signed Rank\n\nA stock analyst believes the median number of shares traded in Walgreens Boots Alliance (WBA) stock is greater than that in McDonald’s (MCD). Test the analyst’s belief at the \\alpha=0.05 level of significance.\n\n\nstocks &lt;- tibble(WBA = c(8.9, 6.3, 6.2, 7.2, 2.8, 3.3, 23.6, \n                         6.0, 15.6, 5.2, 6.3, 10.1, 4.0, 8.4),\n                 MCD = c(8.5, 7.6, 8.3, 10.4, 2.5, 2.6, 3.5, \n                         4.7, 9.0, 6.0, 5.6, 5.0, 4.4, 5.6))\n\n\nRecall the R syntax,\n\n\nwilcox.test(dataset$variable1, dataset$variable2,\n       alternative = \"alternative\",\n       mu = hypothesized_value,\n       paired = TRUE,\n       exact = FALSE)"
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-4",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-4",
    "title": "Wilcoxon Signed Rank",
    "section": "Wilcoxon Signed Rank",
    "text": "Wilcoxon Signed Rank\n\nFrom the problem statement: A stock analyst believes the median number of shares traded in Walgreens Boots Alliance (WBA) stock is greater than that in McDonald’s (MCD).\n\n\nwilcox.test(stocks$WBA, stocks$MCD,\n       alternative = \"greater\",\n       paired = TRUE, \n       exact = FALSE)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  stocks$WBA and stocks$MCD\nV = 69, p-value = 0.1575\nalternative hypothesis: true location shift is greater than 0"
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-5",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wilcoxon-signed-rank-5",
    "title": "Wilcoxon Signed Rank",
    "section": "Wilcoxon Signed Rank",
    "text": "Wilcoxon Signed Rank\n\nHypotheses\n\nH_0: \\ M_{\\text{WBA}} \\le M_{\\text{MCD}} OR M_d \\le 0, where d = \\text{WBA} - \\text{MCD}\nH_1: \\ M_{\\text{WBA}} &gt; M_{\\text{MCD}} OR M_d &gt; 0\n\nTest Statistic and p-Value\n\nV_0 = 69\np = 0.158\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha; \\alpha = 0.05.\n\nConclusion/Interpretation\n\nFail to reject H_0.\nThere is not sufficient evidence to suggest that the median stock shares traded is greater for WBA than for MCD."
  },
  {
    "objectID": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wrap-up",
    "href": "files/lectures/W04-L4-Wilcoxon-signed-rank.html#wrap-up",
    "title": "Wilcoxon Signed Rank",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nToday we reviewed the Wilcoxon signed rank test.\n\nNonparametric alternative to the paired t-test.\n\nThis completes Module 1.\nNext: comparing three or more groups."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#introduction",
    "href": "files/lectures/W02-L1-two-sample-t.html#introduction",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Introduction",
    "text": "Introduction\n\nIn the last lecture, we focused on describing data.\n\nContinuous data: mean with standard deviation, median with interquartile range\nCategorical data: count with percentage\n\nToday, we will focus on drawing conclusions about two population means using data.\n\nConfidence intervals\nHypothesis testing"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-intervals",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-intervals",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\n\n\n\n\n\nPoint Estimate\n\n\nThe single value of a statistic that estimates the value of a parameter.\n\n\n\n\nExamples of point estimates:\nIt is necessary to know how good our estimation is, or to quantify our uncertainty.\n\n\n\n\n\n\n\nConfidence Interval\n\n\nA range of plausible values for the parameter based on values observed in the sample.\n\n\\text{estimate} \\pm \\text{margin of error}\n\n\n\n\n\n\n\n\n\n\nLevel of Confidence\n\n\nThe probability that the interval will capture the true parameter value in repeated samples. i.e., the success rate for the method."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-intervals-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-intervals-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-intervals-2",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-intervals-2",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\n\nBecause CIs are a range of values, we will use interval notation,\n\n\n(lower bound, upper bound)\n\n\nwhere\n\nlower bound = point estimate – margin of error\nupper bound = point estimate + margin of error\n\nMake sure to state your confidence intervals in numeric order.\n\ni.e., the lower bound must be the smaller number and the upper bound must be the larger number."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}",
    "text": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}\n\n\n\n\n\n\n(1-\\alpha)100\\% confidence interval for \\mu_1-\\mu_2\n\n\n\n(\\bar{x}_1 - \\bar{x}_2) \\pm t_{\\alpha/2} \\sqrt{\\frac{s_1^2 }{n_1} + \\frac{s_2^2}{n_2}}\n where t_{\\alpha/2} has \\text{min}(n_1-1, n_2-1) degrees of freedom.\n\n\n\n\nTo construct this interval, we require either:\n\nthe two populations to be normally distributed or\nthe sample sizes are sufficiently large (n_1 \\ge 30 and n_2 \\ge 30)\n\nR syntax:\n\n\nt.test(continuous_variable ~ grouping_variable,\n       data = dataset_name,\n       conf.level = confidence_level)"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}",
    "text": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}\n\nRecall the Palmer penguin data,\n\n\npenguins &lt;- palmerpenguins::penguins"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-2",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-2",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}",
    "text": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}\n\nLet’s find the 95% confidence interval for the difference in average weight (body_mass_g) between male and female (sex) penguins.\nRemember the R syntax:\n\n\nt.test(continuous_variable ~ grouping_variable,\n       data = dataset_name,\n       conf.level = confidence_level) \n\n\nWhat is the continuous variable?\nWhat is the grouping variable?\nWhat is the dataset name?\nWhat is the confidence level?"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-3",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-3",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}",
    "text": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}\n\nLet’s find the 95% confidence interval for the difference in weight (body_mass_g) between male and female penguins.\n\n\nt.test(body_mass_g ~ sex,\n       data = penguins,\n       conf.level = 0.95) \n\n\n    Welch Two Sample t-test\n\ndata:  body_mass_g by sex\nt = -8.5545, df = 323.9, p-value = 4.794e-16\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -840.5783 -526.2453\nsample estimates:\nmean in group female   mean in group male \n            3862.273             4545.685 \n\n\n\nThus, the 95% confidence interval for \\mu_F - \\mu_M is (-840.6, -526.2)."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-4",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-4",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}",
    "text": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}\n\nWhat about the 99% confidence interval for the difference in weight (body_mass_g) between male and female penguins?\n\n\nt.test(body_mass_g ~ sex,\n       data = penguins,\n       conf.level = 0.99) \n\n\nWhat do you expect? Recall that the 95% CI was (-840.6, -526.2)."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-5",
    "href": "files/lectures/W02-L1-two-sample-t.html#confidence-interval-for-mathbfboldsymbol-mu_1-boldsymbolmu_2-5",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}",
    "text": "Confidence Interval for \\mathbf{\\boldsymbol \\mu_1-\\boldsymbol\\mu_2}\n\nWhat about the 99% confidence interval for the difference in weight (body_mass_g) between male and female penguins?\n\n\nt.test(body_mass_g ~ sex,\n       data = penguins,\n       conf.level = 0.99) \n\n\n    Welch Two Sample t-test\n\ndata:  body_mass_g by sex\nt = -8.5545, df = 323.9, p-value = 4.794e-16\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n99 percent confidence interval:\n -890.4112 -476.4124\nsample estimates:\nmean in group female   mean in group male \n            3862.273             4545.685 \n\n\n\nThus, the 99% confidence interval for \\mu_F - \\mu_M is (-890.4, -476.4).\n\nRecall that the 95% CI was (-840.6, -526.2)."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nA friend of yours wants to play a simple coin-flipping game.\n\nIf the coin comes up heads, you win; if it comes up tails, your friend wins.\nSuppose the outcome of five plays of the game is T, T, T, T, T.\nIs your friend cheating?"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nA friend of yours wants to play a simple coin-flipping game.\n\nIf the coin comes up heads, you win; if it comes up tails, your friend wins.\nSuppose the outcome of five plays of the game is T, T, T, T, T.\nIs your friend cheating?\n\nWe know the probability of flipping a tail is 0.5.\nWe can compute the probability of flipping five tails in a row.\n\n\n\n\n\\begin{align*}\n     P[\\text{T, T, T, T, T}] &=  0.5 \\times 0.5 \\times 0.5 \\times 0.5 \\times 0.5 \\\\\n     &= 0.03125\n\\end{align*}\n\n\nIs this probability low enough to believe your friend is cheating?"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-2",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-2",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\n\n\n\n\n\nHypothesis Testing\n\n\nA procedure, based on sample evidence and probability, used to test statements regarding a characteristic of one or more populations.\n\n\n\n\nSteps in hypothesis testing\n\nMake a statement regarding the nature of the population.\nCollect evidence (sample data) to test the statement.\nAnalyze the data to assess the plausibility of the statement.\n\nNote: if we have population parameters available, we do not need to perform a hypothesis test."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-hypotheses",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-hypotheses",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Hypotheses",
    "text": "Hypothesis Testing: Hypotheses\n\n\n\n\n\n\nHypothesis\n\n\nA statement regarding a characteristic of one or more populations.\n\n\n\n\nIn hypothesis testing, we have two hypotheses: the null and the alternative.\n\n\n\n\n\n\n\nNull hypothesis, H_0\n\n\nA statement to be tested.\n\nThis is a statement of no change, no effect, or no difference.\nIt is assumed true until evidence indicates otherwise.\n\n\n\n\n\n\n\n\n\n\nAlternative hypothesis, H_1\n\n\nA statement that we are trying to find evidence to support."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-hypotheses-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-hypotheses-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Hypotheses",
    "text": "Hypothesis Testing: Hypotheses\n\nOne sample tests:\n\nTwo-tailed test\n\nH_0: parameter = some value\nH_1: parameter \\ne some value\n\nLeft-tailed test\n\nH_0: parameter \\ge some value\nH_1: parameter &lt; some value\n\nRight-tailed test\n\nH_0: parameter \\le some value\nH_1: parameter &gt; some value"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-hypotheses-2",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-hypotheses-2",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Hypotheses",
    "text": "Hypothesis Testing: Hypotheses\n\nTwo sample tests\n\nTwo-tailed test\n\nH_0: parameter1 – parameter2 = 0\nH_1: parameter1 – parameter2 \\ne 0\n\nLeft-tailed test\n\nH_0: parameter1 – parameter2 \\ge 0\nH_1: parameter1 – parameter2 &lt; 0\n\nRight-tailed test\n\nH_0: parameter1 – parameter2 \\le 0\nH_1: parameter1 – parameter2 &gt; 0"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-errors",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-errors",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Errors",
    "text": "Hypothesis Testing: Errors\n\nWe use data to draw conclusions about hypotheses.\n\nWe will either reject or fail to reject the null (H_0).\n\nIf we draw the wrong conclusion, we make an error.\nThese can be classified as Type I (\\alpha) or Type II (\\beta) errors.\n\n\\alpha and \\beta are probabilities (i.e., are between 0 and 1)."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-errors-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-errors-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Errors",
    "text": "Hypothesis Testing: Errors\n\nAs stated earlier, Type I (\\alpha) and Type II (\\beta) errors are probabilities.\n\n\\alpha = \\text{P}[\\text{reject } H_0 \\text{ when } H_0 \\text{ is true}]\n\\beta = \\text{P}[\\text{fail to reject } H_0 \\text{ when } H_1 \\text{ is true}]\n\nWe also call \\alpha the level of significance.\nWe should choose \\alpha based on the level of error we are willing to withstand in the experiment.\n\nThe \\alpha that is commonly used is \\alpha=0.05.\nSometimes, smaller \\alpha is used. e.g., clinical trial \\to \\alpha=0.01.\n\nFor a fixed sample size (n), \\alpha and \\beta are inversely related."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-test-statistics",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-test-statistics",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Test Statistics",
    "text": "Hypothesis Testing: Test Statistics\n\nAfter stating our hypotheses, we will construct a test statistic.\nThe choice of test statistic depends on:\n\nThe hypotheses being tested.\nAssumptions made about the data.\n\nThe value of the test statistic depends on the sample data.\n\nIf we were to draw a different sample, we would find a different value for the test statistic.\n\nWe will use the test statistic on our way to drawing conclusions about the hypotheses."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-p-values",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-p-values",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: p-Values",
    "text": "Hypothesis Testing: p-Values\n\n\n\n\n\n\np-value\n\n\nThe probability of observing what we’ve observed or something more extreme, assuming the null hypothesis is true.\n\n\n\n\nAfter constructing test statistics, we will find the corresponding p-value.\nFinding a p-value depends on the distribution being used.\nWe will compare the p-value to \\alpha in order to draw conclusions.\n\nReject H_0 if p &lt; \\alpha."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-conclusions-and-interpretations",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-conclusions-and-interpretations",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Conclusions and Interpretations",
    "text": "Hypothesis Testing: Conclusions and Interpretations\n\nOnce we’ve found the p-value, we can draw a conclusion.\n\nIf p &lt; \\alpha, we reject H_0.\n\nThere is sufficient evidence to suggest that H_1 is true.\n\nIf p \\ge \\alpha, we fail to reject H_0.\n\nThere is not sufficient evidence to suggest that H_1 is true.\n\n\nTake aways:\n\nWe never “accept” the null.\nWe always interpret in terms of H_1."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test",
    "href": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Two-Sample t-Test",
    "text": "Two-Sample t-Test\n\n\n\n\n\n\nHypothesis Test for Two Independent Means\n\n\nHypotheses\n\nH_0: \\mu_1-\\mu_2 = \\mu_0 | H_0: \\mu_1-\\mu_2 \\le \\mu_0 | H_0: \\mu_1-\\mu_2 \\ge \\mu_0\nH_1: \\mu_1-\\mu_2 \\ne \\mu_0 | H_0: \\mu_1 - \\mu_2 &gt; \\mu_0 | H_1: \\mu_1 - \\mu_2 &lt; \\mu_0\n\nTest Statistic \nt_0 = \\frac{(\\bar{x}_1-\\bar{x}_2)-\\mu_0}{\\sqrt{\\frac{s_1^2}{n}+\\frac{s_2^2}{n}}}\n\np-Value\n\np = 2 P[t \\ge |t_0|] | p = P[t \\ge |t_0|] | p = P[t \\le |t_0|]\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha.\n\nConclusion/Interpretation\n\n[Reject or fail to reject] H_0.\nThere [is or is not] sufficient evidence to suggest [alternative hypothesis in words]."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Two-Sample t-Test",
    "text": "Two-Sample t-Test\n\nR syntax:\n\n\nt.test(continuous_variable ~ grouping_variable,\n       data = dataset_name,\n       mu = hypothesized_difference,\n       alternative = alternative)\n\n\nImportant!!\n\nWe are estimating \\mu_1 - \\mu_2, but R is going to subtract in alphabetical or numeric order of the grouping variable.\n\ne.g., if we have “Male” and “Female”, it will estimate \\mu_{\\text{Female}} - \\mu_{\\text{Male}}.\ne.g., if we have “110” and “5”, it will estimate \\mu_{5} - \\mu_{110}.\nIn the case of two-tailed tets, this does not matter… but beware when doing a one-tailed test!"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-example",
    "href": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-example",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Two-Sample t-Test: Example",
    "text": "Two-Sample t-Test: Example\n\nConsider the penguin data. Is there a significant difference in weight (body_mass_g) between male and female penguins? Test at the \\alpha=0.05 level.\nRemember the R syntax:\n\n\nt.test(continuous_variable ~ grouping_variable,\n       data = dataset_name,\n       mu = hypothesized_difference,\n       alternative = alternative)\n\n\nWhat is the continuous variable?\nWhat is the grouping variable?\nWhat is the dataset name?\nWhat is the hypothesized difference?\nWhat is the alternative?"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-example-1",
    "href": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-example-1",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Two-Sample t-Test: Example",
    "text": "Two-Sample t-Test: Example\n\nConsider the penguin data. Is there a significant difference in weight (body_mass_g) between male and female penguins? Test at the \\alpha=0.05 level.\nRemember the R syntax:\n\n\nt.test(body_mass_g ~ sex,\n       data = penguins,\n       mu = 0,\n       alternative = \"two\")\n\n\n    Welch Two Sample t-test\n\ndata:  body_mass_g by sex\nt = -8.5545, df = 323.9, p-value = 4.794e-16\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -840.5783 -526.2453\nsample estimates:\nmean in group female   mean in group male \n            3862.273             4545.685 \n\n\n\nIs this a significant difference?"
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-example-2",
    "href": "files/lectures/W02-L1-two-sample-t.html#two-sample-t-test-example-2",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Two-Sample t-Test: Example",
    "text": "Two-Sample t-Test: Example\nHypotheses\n\nH_0: \\mu_1-\\mu_2 = 0\nH_1: \\mu_1-\\mu_2 \\ne 0\n\nTest Statistic and p-Value\n\nt_0 = -8.55\np &lt; 0.001\n\nRejection Region\n\nReject H_0 if p &lt; \\alpha; \\alpha=0.05.\n\nConclusion/Interpretation\n\nReject H_0.\nThere is sufficient evidence to suggest that male and female penguins have different weights."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-practical-vs.-statistical-significance",
    "href": "files/lectures/W02-L1-two-sample-t.html#hypothesis-testing-practical-vs.-statistical-significance",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Hypothesis Testing: Practical vs. Statistical Significance",
    "text": "Hypothesis Testing: Practical vs. Statistical Significance\n\nHypothesis testing depends on sample size.\nAs the sample size increases, our p-values decrease necessarily.\nAs p-values decrease, we are more likely to reject the null hypothesis.\nWe must ask ourselves if the value we are testing against makes practical sense.\n\nA new weight loss medication where the average amount of weight loss was 1 lb over 6 months.\nA new weight loss medication where the average amount of weight lost was 15 lb over 6 months.\nA new teaching method that raised final exam scores by 2 points.\nA new teaching method that raised final exam scores by 15 points."
  },
  {
    "objectID": "files/lectures/W02-L1-two-sample-t.html#wrap-up",
    "href": "files/lectures/W02-L1-two-sample-t.html#wrap-up",
    "title": "Review: Inferential Statistics & Two-Sample t-Tests",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nToday we reviewed statistical inference.\n\nConfidence intervals\nHypothesis testing\n\nGet to know you quiz - complete with RStudio - due today.\nNext meeting: how to conceptualize research questions; dependent t-test."
  }
]