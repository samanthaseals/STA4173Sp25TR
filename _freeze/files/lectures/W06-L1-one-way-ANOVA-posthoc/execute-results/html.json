{
  "hash": "e0d3f12d816b4c0ac308d969d5c7c931",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"**One-Way Analysis of Variance**\"\nsubtitle: \"**STA4173: Biostatistics** <br> Spring 2025\"\nformat: \n  revealjs: \n    code-overflow: wrap\n    df-print: paged\n    embed-resources: true\n    slide-number: true\n    width: 1600\n    height: 900\n    html-math-method: katex\n    theme:\n      - default\nexecute:\n  echo: true\n  warning: false\n  message: false\n  error: true\neditor: source\n---\n\n\n\n## Introduction: Analysis of Variance\n\n- We have previously discussed testing the difference between two groups.\n\n    - What about when there are three or more groups? \n\n- We will use a method called **an**alysis **o**f **va**riance (ANOVA).\n\n    - This method partitions the variance of the outcome into variance due to the groups and variance due to \"other\" factors.\n\n- Fun fact: the two-sample *t*-test is a special case of ANOVA.\n\n    - If you perform ANOVA when comparing two means, you will obtain the same results as the two-sample *t*-test.\n\n## Hypotheses\n\n- Hypotheses all take the same form:\n\n    - $H_0: \\ \\mu_1 = \\mu_2 = ... = \\mu_k$\n    - $H_1:$ at least one is different\n\n- Note 1: you must fill in the \"k\" when writing hypotheses!\n\n    - e.g., if there are four means, your hypotheses are\n    \n        - $H_0: \\ \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4$\n        - $H_1:$ at least one is different\n\n- Note 2: ANOVA does not tell us which means are different, just if a general difference exists!\n\n## ANOVA Table\n\n- The computations for ANOVA are more involved than what we've seen before.  \n\n- An ANOVA table will be constructed in order to perform the hypothesis test.\n\n| **Source** | **Sum of Squares** | **df** | **Mean Squares** | ***F*** |\n|-|-|-|-|-|\nTreatment | SS<sub>Trt</sub> | df<sub>Trt</sub> | MS<sub>Trt</sub> | *F*<sub>0</sub>\nError | SS<sub>E</sub> | df<sub>E</sub> | MS<sub>E</sub> |\nTotal | SS<sub>Tot</sub> | df<sub>Tot</sub> | | |\n\n- Once this is put together, we can perform the hypothesis test.\n\n    - Our test statistic is the *F*<sub>0</sub>.\n    \n## The *F* Distribution\n\n- The *F* distribution is derived as the ratio of two variances. \n\n    - The variances each have degrees of freedom: df<sub>numerator</sub> and df<sub>denominator</sub>\n\n- The *F* distribution's shape depends on the df,\n\n<center><img src=\"images/L08a.png\"></center>\n\n## ANOVA Computations\n\n- Again, here's where we are headed with our computations: \n\n| **Source** | **Sum of Squares** | **df** | **Mean Squares** | ***F*** |\n|-|-|-|-|-|\nTreatment | SS<sub>Trt</sub> | df<sub>Trt</sub> | MS<sub>Trt</sub> | *F*<sub>0</sub>\nError | SS<sub>E</sub> | df<sub>E</sub> | MS<sub>E</sub> |\nTotal | SS<sub>Tot</sub> | df<sub>Tot</sub> | | |\n\n- We are partitioning the variance of our outcome into:\n\n    - Variance due to the grouping (treatment)\n    - Variance due to \"other\" factors (error)\n\n        - Think of this like a \"catch all\" for other sources of error -- things we did not adjust for in our model.\n\n## ANOVA Computations\n\n- Before we begin our computations, it would be helpful if we know \n\n$$ \\bar{x}, \\ \\ n_i, \\ \\ \\bar{x}_i, \\ \\ s_i^2 $$ \n\n- where,\n    - $\\bar{x}$ is the overall mean,\n    - $n_i$ is the sample size for group $i$,\n    - $\\bar{x}_i$ is the mean for group $i$, and\n    - $s_i^2$ is the variance for group $i$\n\n## ANOVA Computations\n\n- We begin our computations with the sums of squares: \n\n$$\n\\begin{align*}\n    \\text{SS}_{\\text{Trt}} &= \\sum_{i=1}^k n_i(\\bar{x}_i-\\bar{x})^2 \\\\\n    \\text{SS}_{\\text{E}} &= \\sum_{i=1}^k (n_i-1)s_i^2 \\\\\n    \\text{SS}_{\\text{Tot}} &= \\text{SS}_{\\text{Trt}} + \\text{SS}_{\\text{E}}\n\\end{align*} \n$$ \n    \n- and each sum of squares has degrees of freedom: \n    - $\\text{df}_{\\text{Trt}} = k-1$ (number of groups -- 1)\n    - $\\text{df}_{\\text{E}} = n-k$ (overall sample size -- number of groups)\n    - $\\text{df}_{\\text{Tot}} = n-1$ (overall sample size -- 1) = $\\text{df}_{\\text{Trt}} + \\text{df}_{\\text{E}}$ \n    \n## ANOVA Computations\n\n- Once we have the sum of squares and corresponding degrees of freedom, we have the mean squares.\n\n- Generally, mean squares are the sum of square divided by the df,\n$$ \\text{MS}_X = \\frac{\\text{SS}_X}{\\text{df}_X}$$\n\n- In the case of one-way ANOVA,\n$$\n\\begin{align*}\n    \\text{MS}_{\\text{Trt}} &= \\frac{\\text{SS}_{\\text{Trt}}}{\\text{df}_{\\text{Trt}}} \\\\\n    \\text{MS}_{\\text{E}} &= \\frac{\\text{SS}_{\\text{E}}}{\\text{df}_{\\text{E}}}\n\\end{align*}\n$$\n    - Note that there is **no** $\\text{MS}_{\\text{Tot}}$! \n\n## ANOVA Computations\n\n- Finally, we have the test statistic. \n\n- Generally, we construct an $F$ for ANOVA by dividing the MS of interest by MS$_{\\text{E}}$,\n$$ F_X = \\frac{\\text{MS}_X}{\\text{MS}_{\\text{E}}} $$\n\n- In one-way ANOVA, we are only constructing the $F$ for treatment,\n$$F_0 = \\frac{\\text{MS}_{\\text{Trt}}}{\\text{MS}_{\\text{E}}} $$\n\n## ANOVA Computations\n\n- We are finally done constructing our ANOVA table! As a reminder,\n\n| **Source** | **Sum of Squares** | **df** | **Mean Squares** | ***F*** |\n|-|-|-|-|-|\nTreatment | SS<sub>Trt</sub> | df<sub>Trt</sub> | MS<sub>Trt</sub> | *F*<sub>0</sub>\nError | SS<sub>E</sub> | df<sub>E</sub> | MS<sub>E</sub> |\nTotal | SS<sub>Tot</sub> | df<sub>Tot</sub> | | |    \n\n## ANOVA: R Syntax\n\n- We can use the `aov()` and `summary()` functions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- aov(continuous_variable ~ grouping_variable,\n         data = dataset_name)\nsummary(m)\n```\n:::\n\n\n\n\n- However, note that ANOVA is regression (and regression is ANOVA).\n    - We can also use `lm()` to define the model and `anova()` to construct the ANOVA table.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- lm(continuous_variable ~ grouping_variable,\n         data = dataset_name)\nanova(m)\n```\n:::\n\n\n\n\n\n## Example - Dental\n\n- Prosthodontists specialize in the restoration of oral function, including the use of dental implants, veneers, dentures, and crowns. A researcher wanted to compare the shear bond strength of different repair kits for repairs of chipped porcelain veneer. \n\n- He randomly divided 20 porcelain specimens into four treatment groups: group 1 used the Cojet system, group 2 used the Silistor system, group 3 used the Cimara system, and group 4 used the Ceramic Repair system. \n    \n- At the conclusion of the study, shear bond strength (in megapascals, MPa) was measured according to ISO 10477. The data are as follows,\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nstrength <- c(15.4, 12.9, 17.2, 16.6, 19.3,\n              17.2, 14.3, 17.6, 21.6, 17.5,\n               5.5,  7.7, 12.2, 11.4, 16.4,\n              11.0, 12.4, 13.5,  8.9,  8.1)\nsystem <- c(rep(\"Cojet\",5), rep(\"Silistor\",5), rep(\"Cimara\",5), rep(\"Ceramic\",5))\ndata <- tibble(system, strength)\n```\n:::\n\n\n\n## Example - Dental\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"system\"],\"name\":[1],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"strength\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"Cojet\",\"2\":\"15.4\"},{\"1\":\"Cojet\",\"2\":\"12.9\"},{\"1\":\"Cojet\",\"2\":\"17.2\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n- What is the continuous variable?\n\n- What is the grouping variable?\n\n## Example - Dental\n\n- Our first step will be to construct an ANOVA table for the data.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- aov(strength ~ system, data = data)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nm2 <- lm(strength ~ system, data = data)\nanova(m2)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"Sum Sq\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Mean Sq\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"3\",\"2\":\"199.9855\",\"3\":\"66.66183\",\"4\":\"7.545199\",\"5\":\"0.002294591\",\"_rn_\":\"system\"},{\"1\":\"16\",\"2\":\"141.3600\",\"3\":\"8.83500\",\"4\":\"NA\",\"5\":\"NA\",\"_rn_\":\"Residuals\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n\n## Hypothesis Testing\n\n- **Hypotheses**\n\n    - $H_0: \\ \\mu_1 = \\mu_2 = ... = \\mu_k$ \n    - $H_1:$ at least one mean is different\n\n- **Test Statistic**\n\n    - $F_0$ (pulled from the ANOVA table)\n\n- ***p*-Value**\n\n    - $p = P[F_0 \\ge F_{\\text{df}_{\\text{Trt}}, \\text{df}_{\\text{E}}}]$\n    \n- **Rejection Region**\n\n    - Reject $H_0$ if $p<\\alpha$.\n\n## Example - Dental\n\n- Using the dental data:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n- Determine if there is a difference in average strength between the groups. Test at the $\\alpha=0.01$ level.\n\n## Example - Dental\n\n- **Hypotheses**\n\n    - $H_0: \\ \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4$ \n    - $H_1:$ at least one mean is different\n\n- **Test Statistic and *p*-Value**\n\n    - $F_0 = 7.545$\n    - $p = 0.002$\n    \n- **Rejection Region**\n\n    - Reject $H_0$ if $p<\\alpha$; $\\alpha = 0.01$.\n    \n- **Conclusion/Interpretation**\n\n    - Reject $H_0$. There is sufficient evidence to suggest that there is a difference in average strength between the four groups.\n    \n## Introduction: Posthoc Testing\n\n- Today we have introduced ANOVA. Recall the hypotheses,\n\n    - $H_0: \\mu_1 = \\mu_2 = ... = \\mu_k$\n    - $H_1:$ at least one $\\mu_i$ is different\n    \n- The $F$ test does not tell us *which* mean is different... only that a difference exists.\n\n- In theory, we could perform repeated $t$ tests to determine pairwise differences.\n\n    - Recall that ANOVA is an extension of the $t$ test... or that the $t$ test is a special case of ANOVA.\n    \n    - However, this will increase the Type I error rate ($\\alpha$).\n\n## Introduction: Posthoc Testing\n\n- Recall that the Type I error rate, $\\alpha$, is the probability of *incorrectly* rejecting $H_0$.\n\n    - i.e., we are saying there is a difference between the means when there is actually *not* a difference.\n    \n- Suppose we are comparing 5 groups.\n\n    - This is 10 pairwise comparisons!! \n        \n        - 1-2, 1-3, 1-4, 1-5, 2-3, 2-4, 2-5, 3-4, 3-5, 4-5\n        \n    - If we perform repeated $t$ tests under $\\alpha=0.05$, we are inflating the Type I error to 0.40! ðŸ˜µ\n\n## Introduction: Posthoc Testing\n\n- When performing posthoc comparisons, we can choose one of two paths:\n\n    - Control the Type I (familywise) error rate.\n    - Do not control the Type I error rate.\n    \n- Note that controlling the Type I error rate is more conservative than when we do not control it.\n\n    - \"Conservative\" = more difficult to reject.\n    \n- Generally, statisticians:\n\n    - *do not* control the Type I error rate if examining the results of pilot/preliminary studies that are exploring for general relationships.\n    \n    - *do* control the Type I error rate if examining the results of confirmatory studies and are attempting to confirm relationships observed in pilot/preliminary studies.\n    \n## Introduction: Posthoc Testing\n\n- The posthoc tests we will learn:\n\n    - Tukey's test\n    \n        - Performs all pairwise tests and controls the Type I error rate\n        \n    - Fisher's least significant difference \n    \n        - Performs all pairwise tests but does not control the Type I error rate\n        \n    - Dunnett's test\n    \n        - Compares each group to a control group and controls the Type I error rate\n        \n- **Caution**: we should *only* perform posthoc tests if we have determined that a general difference exists!\n\n    - i.e., we rejected when looking at the $F$ test in ANOVA\n    \n## Example\n\n- Recall the dental example from earlier,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm1 <- aov(strength ~ system, data = data)\nsummary(m1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n- Are we justified in posthoc testing? (Recall: $\\alpha=0.01$).\n\n## Tukey's Test\n\n- Tukey's test allows us to do all pairwise comparisons while controlling $\\alpha$.\n\n- The underlying idea of the comparison:\n\n    - We declare $\\mu_i \\ne \\mu_j$ if $|\\bar{y}_i - \\bar{y}_j| \\ge W$, where $$ W = \\frac{q_{\\alpha}(k, \\text{df}_{\\text{E}})}{\\sqrt{2}} \\sqrt{\\text{MSE} \\left( \\frac{1}{n_i} + \\frac{1}{n_j} \\right)} $$\n    \n        - $q_{\\alpha}(k, \\text{df}_{\\text{E}})$ is the critical value from the Studentized range distribution.\n\n- We will use the [`TukeyHSD()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/TukeyHSD) function.\n\n    - Note that this requires us to have created our model using the `aov()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- aov(continuous_variable ~ grouping_variable, data = dataset_name)\nTukeyHSD(m)$grouping_variable\n```\n:::\n\n\n\n\n## Tukey's Test\n\n- Let's apply Tukey's to the dental data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- aov(strength ~ system, data = data)\nTukeyHSD(m, conf.level = 0.99)$system\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  diff         lwr       upr       p adj\nCimara-Ceramic   -0.14 -7.04151507  6.761515 0.999845202\nCojet-Ceramic     5.50 -1.40151507 12.401515 0.044147158\nSilistor-Ceramic  6.86 -0.04151507 13.761515 0.010458208\nCojet-Cimara      5.64 -1.26151507 12.541515 0.038206781\nSilistor-Cimara   7.00  0.09848493 13.901515 0.008990873\nSilistor-Cojet    1.36 -5.54151507  8.261515 0.886304336\n```\n\n\n:::\n:::\n\n\n\n- Which are significantly different at the $\\alpha=0.01$ level?\n\n\n## Fisher's Test\n\n- Fisher's allows us to test all pairwise comparisons but \\textbf{does not} control the $\\alpha$.\n\n- The underlying idea of the comparison:\n\n    - We declare $\\mu_i \\ne \\mu_j$ if $|\\bar{y}_i - \\bar{y}_j| \\ge \\text{LSD}$, where $$ \\text{LSD} = t_{1-\\alpha/2, \\text{df}_\\text{E}} \\sqrt{\\text{MSE} \\left( \\frac{1}{n_i} + \\frac{1}{n_j} \\right)} $$\n\n- We will use the [`LSD.test()`](https://www.rdocumentation.org/packages/agricolae/versions/1.3-5/topics/LSD.test) function from the [`agricolae`](https://www.rdocumentation.org/packages/agricolae/versions/1.3-5) package.\n\n    - Note that, like Tukey's, this requires us to have created our model using the `aov()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(agricolae)\nresults <- summary(m)\n(LSD.test(dataset_name$continuous_variable, # continuous outcome\n          dataset_name$grouping_variable, # grouping variable\n          results[[1]]$Df[2], # df_E\n          results[[1]]$`Mean Sq`[2], # MSE\n          alpha = alpha_level) # can omit if alpha = 0.05\n  )[5] # limit to only the pairwise comparison results\n```\n:::\n\n\n\n## Fisher's Test\n\n- Let's apply Fisher's to the dental data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(agricolae)\nresults <- summary(m)\nLSD.test(data$strength, \n         data$system, \n         results[[1]]$Df[2], \n         results[[1]]$`Mean Sq`[2],\n         alpha = 0.01)[5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$groups\n         data$strength groups\nSilistor         17.64      a\nCojet            16.28      a\nCeramic          10.78      b\nCimara           10.64      b\n```\n\n\n:::\n:::\n\n\n\n- Which are significantly different at the $\\alpha=0.01$ level?\n \n\n## Dunnett's Test \n\n- Dunnett's test allows us to do all pairwise comparisons against only the control, while controlling $\\alpha$.\n\n    - This has fewer comparisons than Tukey's because we are not comparing non-control groups to one another.\n    \n    - i.e., we are sharing the $\\alpha$ between fewer comparisons now, which is preferred if we are not interested in the comparisons between non-control groups.\n\n- The underlying idea of the comparison:\n\n    - We declare $\\mu_i \\ne \\mu_j$ if $|\\bar{y}_i - \\bar{y}_j| \\ge D$, where $$ D = d_{\\alpha}(k-1, \\text{df}_{\\text{E}}) \\sqrt{\\text{MSE} \\left( \\frac{1}{n_i} + \\frac{1}{n_c} \\right)}, $$\n        \n        - $d_{\\alpha}(k-1, \\text{df}_{\\text{E}})$ is the critical value from Dunnett's table.\n\n## Dunnett's Test \n\n- We will use the [`DunnettTest()`](https://www.rdocumentation.org/packages/DescTools/versions/0.99.32/topics/DunnettTest) function from the DescTools package to perform Dunnett's test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DescTools)\nDunnettTest(x=dataset_name$continuous_variable, \n            g=dataset_name$grouping_variable, \n            control = \"name of control group\")\n```\n:::\n\n\n\n- The *p*-values are adjusted, so you can directly compare them to the specified $\\alpha$.\n\n## Dunnett's Test\n\n- Let's apply Dunnett's to the dental data.\n\n    - We will treat \"Ceramic\" as the control group.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DescTools)\nDunnettTest(x=data$strength, \n            g=data$system, \n            control = \"Ceramic\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  Dunnett's test for comparing several treatments with a control :  \n    95% family-wise confidence level\n\n$Ceramic\n                  diff     lwr.ci    upr.ci   pval    \nCimara-Ceramic   -0.14 -5.0138317  4.733832 0.9997    \nCojet-Ceramic     5.50  0.6261683 10.373832 0.0259 *  \nSilistor-Ceramic  6.86  1.9861683 11.733832 0.0059 ** \n\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n- Which are significantly different at the $\\alpha=0.01$ level?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}