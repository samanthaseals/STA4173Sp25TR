{
  "hash": "9e1093f2c85b079b6fc5714050863238",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"**ANOVA Assumptions and <br> Kruskal-Wallis**\"\nsubtitle: \"**STA4173: Biostatistics** <br> Spring 2025\"\nformat: \n  revealjs: \n    code-overflow: wrap\n    df-print: paged\n    embed-resources: true\n    slide-number: true\n    width: 1600\n    height: 900\n    html-math-method: katex\n    theme:\n      - default\nexecute:\n  echo: true\n  warning: false\n  message: false\n  error: true\neditor: source\n---\n\n\n\n## Introduction: ANOVA Assumptions\n\n- We previously discussed testing three or more means using ANOVA.\n\n- We also discussed that ANOVA is an extension of the two-sample *t*-test.\n\n- Recall that the *t*-test has two assumptions:\n\n    - Equal variance between groups.\n    \n    - Normal distribution.\n    \n- We will extend our knowledge of checking assumptions today.    \n\n## ANOVA Assumptions: Definition\n\n- We can represent ANOVA with the following model:\n\n$$ y_{ij} = \\mu + \\tau_i + \\varepsilon_{ij} $$\n\n- where:\n\n    - $y_{ij}$ is the $j^{\\text{th}}$ observation in the $i^{\\text{th}}$ group,\n    - $\\mu$ is the overall (grand) mean,\n    - $\\tau_i$ is the treatment effect for group $i$, and\n    - $\\varepsilon_{ij}$ is the error term for the $j^{\\text{th}}$ observation in the $i^{\\text{th}}$ group.\n    \n## ANOVA Assumptions: Definition\n\n- We assume that the error term follows a normal distribution with mean 0 and a constant variance, $\\sigma^2$. i.e.,\n$$\\varepsilon_{ij} \\overset{\\text{iid}}{\\sim} N(0, \\sigma^2)$$\n\n- Very important note: **the assumption is on the error term** and NOT on the outcome!\n\n- We will use the residual (the difference between the observed value and the predicted value) to assess assumptions:\n$$ e_{ij} = y_{ij} - \\hat{y}_{ij} $$\n\n## ANOVA Assumptions: Graphical Assessment\n    \n- **Normality**: quantile-quantile plot\n\n    - Should have points close to the 45$^\\circ$ line\n    - We will focus on the \"center\" portion of the plot\n    \n- **Variance**: scatterplot of the residuals against the predicted values\n\n    - Should be \"equal spread\" between the groups\n    - No \"pattern\"\n\n## ANOVA Assumptions: Graphical Assessment\n\n- Like with *t*-tests, we will assess these assumptions graphically.\n\n- We will return to the `classpackage` package and use the `anova_check()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(classpackage) \nanova_check(m)\n```\n:::\n\n\n\n## ANOVA Assumptions: Graphical Assessment\n\n- Recall the dental example from last week,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nstrength <- c(15.4, 12.9, 17.2, 16.6, 19.3,\n              17.2, 14.3, 17.6, 21.6, 17.5,\n               5.5,  7.7, 12.2, 11.4, 16.4,\n              11.0, 12.4, 13.5,  8.9,  8.1)\nsystem <- c(rep(\"Cojet\",5), rep(\"Silistor\",5), rep(\"Cimara\",5), rep(\"Ceramic\",5))\ndata <- tibble(system, strength)\nm <- aov(strength ~ system, data = data)\nsummary(m)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value  Pr(>F)   \nsystem       3  200.0   66.66   7.545 0.00229 **\nResiduals   16  141.4    8.84                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n\n## ANOVA Assumptions: Assessing Graphically\n\n- Let's assess the assumptions,\n\n<center>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(classpackage)\nanova_check(m)\n```\n\n::: {.cell-output-display}\n![](W07-L1-ANOVA-assumptions-Kruskal-Wallis_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n</center>\n\n## ANOVA Assumptions: Test for Variance\n\n- We can formally check the variance assumption with the Brown-Forsythe-Levine test.\n\n    - This test transforms the data and then performs ANOVA!\n    \n- The test statistic is calculated as follows, $$ F_0 = \\frac{\\sum_{i=1}^k n_i (\\bar{z}_i - \\bar{z})^2/(k-1)}{\\sum_{i=1}^k \\sum_{j=1}^{n_j}(z_{ij}-\\bar{z}_i)^2/(n-k) }, $$ where\n\n    - $k$ is the number of groups,\n    - $n_i$ is the sample size of group i,\n    - $n = \\sum_{i=1}^k n_i$, and\n    - $z_{ij} = |y_{ij} - \\text{median}(y_i)|$\n\n## ANOVA Assumptions: Test for Variance\n\n- **Hypotheses**\n\n    - $H_0: \\ \\sigma^2_1 = ... = \\sigma^2_k$\n    - $H_1:$ at least one $\\sigma^2_i$ is different\n\n- **Test Statistic**\n\n    - $F_0$ (take from resulting ANOVA table)\n    \n- ***p*-Value**\n\n    - $p = P[F_{\\text{df}_{\\text{Trt}}, \\text{df}_{\\text{E}}} \\ge F_0]$\n    \n- **Rejection Region**\n\n    - Reject if $p < \\alpha$.\n  \n## ANOVA Assumptions: Test for Variance\n\n- We will use the [`leveneTest()`](https://www.rdocumentation.org/packages/car/versions/3.1-0/topics/leveneTest) function from the [`car`](https://www.rdocumentation.org/packages/car/versions/3.1-0) package.\n\n    - Note: I do not load the `car` package because it overwrites a necessary function in `tidyverse`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::leveneTest(model_results)\n```\n:::\n\n\n\n- In our dental example,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncar::leveneTest(m)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"\"],\"name\":[\"_rn_\"],\"type\":[\"\"],\"align\":[\"left\"]},{\"label\":[\"Df\"],\"name\":[1],\"type\":[\"int\"],\"align\":[\"right\"]},{\"label\":[\"F value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Pr(>F)\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"3\",\"2\":\"0.7339467\",\"3\":\"0.5468532\",\"_rn_\":\"group\"},{\"1\":\"16\",\"2\":\"NA\",\"3\":\"NA\",\"_rn_\":\"\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\n\n## ANOVA Assumptions: Test for Variance\n\n- **Hypotheses**\n\n    - $H_0: \\ \\sigma^2_1 = \\sigma^2_2 = \\sigma^2_3 = \\sigma^2_4$\n    - $H_1:$ at least one $\\sigma^2_i$ is different\n\n- **Test Statistic and *p*-Value**\n\n    - $F_0 = 0.734$\n    - $p = 0.547$\n    \n- **Rejection Region**\n\n    - Reject if $p < \\alpha$; $\\alpha=0.01$.\n    \n- **Conclusion/Interpretation**\n\n    - Fail to reject $H_0$. There is not sufficient evidence to suggest that the variances are different (i.e., the variance assumption is not broken).\n\n## Introduction: Kruskal-Wallis\n\n- We just discussed the ANOVA assumptions.\n\n$$\\varepsilon_{ij} \\overset{\\text{iid}}{\\sim} N(0, \\sigma^2)$$\n\n- We also discussed how to assess the assumptions:\n\n    - Graphically using the `anova_check()` function.\n    \n    - Confirming the variance assumption using the BFL.\n\n- If we break an assumption, we will turn to the nonparametric alternative, the Kruskal-Wallis.\n\n## Kruskal-Wallis Test\n\n- If we break ANOVA assumptions, we should implement the nonparametric version, the Kruskal-Wallis.\n\n- The Kruskal-Wallis test determines if $k$ independent samples come from populations with the same distribution. \n\n- Our new hypotheses are\n\n    - $H_0: M_1 = ... = M_k$\n    - $H_1:$ at least one $M_i$ is different\n\n## Kruskal-Wallis Test\n\n- The test statistic is as follows: \n\n$$ \\chi^2_0 = \\frac{12}{n(n+1)} \\sum_{i=1}^k \\frac{R_i^2}{n_i} - 3(n+1), $$ \n\n- where\n    \n    - $R_i$ is the sum of the ranks for group $i$,\n    - $n_i$ is the sample size for group $i$,\n    - $n = \\sum_{i=1}^k n_i$ = total sample size, and\n    - $k$ is the number of groups.\n\n- $H$ follows a $\\chi^2$ distribution with $k-1$ degrees of freedom.\n\n## Kruskal-Wallis Test\n\n- **Hypotheses**\n\n    - $H_0: \\ M_1 =  ... = M_k$\n    - $H_1:$ at least one $M_i$ is different\n  \n- **Test Statistic**\n\n    - $\\chi^2_0 = \\frac{12}{n(n+1)} \\sum_{i=1}^k \\frac{R_i^2}{n_i} - 3(n+1)$ \n  \n- ***p*-Value**\n\n    - $p = P[\\chi^2_{k-1} \\ge \\chi^2_0]$\n\n- **Rejection Region**\n\n    - Reject $H_0$ if $p < \\alpha$\n  \n## Kruskal-Wallis Test\n\n- We will use the [`kruskal.test()`](https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/kruskal.test) function to perform the Kruskal-Wallis test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal.test(continuous_variable ~ grouping_variable, \n             data = dataset_name)\n```\n:::\n\n\n\n- Applying this to our dental dataset,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskal.test(strength ~ system, data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tKruskal-Wallis rank sum test\n\ndata:  strength by system\nKruskal-Wallis chi-squared = 12.515, df = 3, p-value = 0.005812\n```\n\n\n:::\n:::\n\n\n\n## Example\n\n- **Hypotheses**\n\n    - $H_0: \\ M_1 = M_2 = M_3 = M_4$\n    - $H_1:$ at least one $M_i$ is different\n  \n- **Test Statistic and *p*-Value**\n\n    - $\\chi_0^2 = 12.515$ \n    - $p = 0.006$\n\n- **Rejection Region**\n\n    - Reject $H_0$ if $p < \\alpha$; $\\alpha=0.01$.\n  \n- **Conclusion/Interpretation**\n\n    - Reject $H_0$. There is sufficient evidence to suggest that there is a difference in strength between the four systems.\n\n## Kruskal-Wallis: Posthoc Testing\n\n- We can also perform posthoc testing in the Kruskal-Wallis setting.\n\n- The set up is just like Tukey's -- we can perform all pairwise comparisons and control for the Type I error rate.\n\n- Instead of using $|\\bar{y}_i - \\bar{y}_j|$, we will use $|\\bar{R}_i - \\bar{R}_j|$, where $\\bar{R}_i$ is the average rank of group $i$.\n\n- The comparison we are making:\n\n    - We declare $M_i \\ne M_j$ if $|\\bar{R}_i - \\bar{R}_j| \\ge KW$, where\n    $$ KW = \\frac{q_{\\alpha}(k, \\infty)}{\\sqrt{2}} \\sqrt{\\frac{n(n+1)}{12} \\left( \\frac{1}{n_i} + \\frac{1}{n_j} \\right)} $$ and $q_{\\alpha}(k, \\infty)$ is the critical value from the Studentized range distribution.\n\n## Kruskal-Wallis: Posthoc Testing\n\n- We will use the [`kruskalmc()`](https://www.rdocumentation.org/packages/pgirmess/versions/2.0.0/topics/kruskalmc) function from the [`pgirmess` package](https://www.rdocumentation.org/packages/pgirmess/versions/2.0.0) to perform the Kruskal-Wallis post-hoc test.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkruskalmc(continuous_variable ~ grouping_variable, \n          data = dataset_name)\n```\n:::\n\n\n\n- In our example,\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pgirmess) \nkruskalmc(strength ~ system, data = data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nMultiple comparison test after Kruskal-Wallis \nalpha: 0.05 \nComparisons\n                 obs.dif critical.dif stat.signif\nCeramic-Cimara       0.2     9.871455       FALSE\nCeramic-Cojet        7.9     9.871455       FALSE\nCeramic-Silistor    10.3     9.871455        TRUE\nCimara-Cojet         8.1     9.871455       FALSE\nCimara-Silistor     10.5     9.871455        TRUE\nCojet-Silistor       2.4     9.871455       FALSE\n```\n\n\n:::\n:::\n\n\n\n- Which pairs are significantly different?\n\n## Wrap Up\n\n- Today we have talked about assessing ANOVA assumptions and performing the nonparametric alternative, the Kruskal-Wallis.\n\n- Per usual, we should only look at posthoc testing when we've detected an overall difference with the Kruskal-Wallis.\n\n- Next lecture: two-way ANOVA.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "W07-L1-ANOVA-assumptions-Kruskal-Wallis_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}